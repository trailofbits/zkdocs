[{"id":0,"href":"/docs/zkdocs/protocol-primitives/random-sampling/","title":"Random Sampling","section":"Protocol primitives","content":" Random sampling # In most protocols, it is necessary to sample uniformly from groups like $\\zq$ or $\\zqs$. Here we will describe how to sample in these specific groups, and a general procedure to sample via rejection sampling.\nWhen available it is advisable to use a cryptographic random number library to securely sample at uniform from a range. For example, to sample uniformly from $\\zq$ (or equivalently $\\range{q}$) in Python, use the secrets library.\n1 2 3 4 import secrets def sample_Zq(): return secrets.randbelow(q) Sampling from $\\zq$ # Sampling uniformly from $\\zq$ is equivalent to sampling uniformly from the set of representatives, i.e. the range $\\range{q}$. We present two secure methods for doing so: wide modular reduction gives samples from an almost-uniform distribution with a (deterministic) logarithmic number of random bits, while rejection sampling gives samples from a truly uniform distribution using a logarithmic number of bits with high probability.\nAlmost-uniform sampling in $\\zq$ using modular reduction # Suppose we only have a cryptographically-secure random bit generator and we would like to sample uniformly from the range $[q]$. As an example we will use the secp256k1 curve order $$ q = 2^{256} - 432420386565659656852420866394968145599 $$\nNever do this:\n1 2 3 def wrong_sampling(): q = 2**256 - 432420386565659656852420866394968145599 return randbits(256) % q The wrong_sampling function introduces non-negligible modulo-bias in the generation of elements, and some elements will be detectably more likely to appear than others. If the random number is used as an ECDSA nonce, this may be enough to fully compromise the key.\nInstead, sample at least 512 bits:\n1 2 3 4 from secrets import randbits def correct_sampling(): q = 2**256 - 432420386565659656852420866394968145599 return randbits(512) % q In general, if the overall security level of your system is $\\lambda$ bits (e.g., 128), then to safely sample from the range $[q]$ where $2^{n-1} \u0026lt; q \u0026lt; 2^{n}$, it is necessary to reduce $n + \\lambda$ cryptographically random bits mod $q$.\nModulo Bias # A common approach to sampling from a range $[q]$ is to generate a random bit string $b \\in \\{0,1\\}^n$, interpret it as a natural number in the range $[2^n - 1]$, then return $x = b\\mod q$. However, this process introduces modulo bias. As a simple example where $q = 3, n = 2$, let $b$ be uniformly drawn from $\\{0,1\\}^2 \\cong [4]$ and let $x = b \\mod 3$. Then $$ \\begin{align*} \u0026amp;\\Pr[x = 0] = \\Pr[b = 0 \\vee b = 3] = 1/2\\\\ \u0026amp;\\Pr[x = 1] = \\Pr[b = 1] = 1/4\\\\ \u0026amp;\\Pr[x = 2] = \\Pr[b = 2] = 1/4\\\\ \u0026amp;\\end{align*} $$\nIntuitively, the bias arises because some elements of $\\zq$ are double-counted. In order to minimize the modulo bias, we can increase the number of random bits drawn. For $q = 3$ and $n = 8$, $$\\Pr[x = 0] = \\frac{86}{256} = \\frac{1}{3} + \\frac{1}{384}$$\nFor $n = 256$ $$\\Pr[x = 0] = \\frac{1}{3} + \\frac{1}{3\\cdot 2^{255}}$$ No real-world adversary can distinguish the distribution generated in the $n = 256$ case from the uniform distribution on $\\mathbb{Z}_3$.\nIn general, if $q$ is an $n$-bit integer, i.e. $2^{n-1} \\leq q \u0026lt; 2^n$ and $X$ is a random variable drawn uniformly from $[2^{n + \\lambda}]$ where $\\lambda \\in \\mathbb{N}$ is some security parameter, then for any $a \\in \\range{q}$\n$$ \\left|\\Pr[X \\equiv a \\mod q] - \\frac{1}{q}\\right| \\leq \\frac{1}{2^{\\lambda}} $$\nIn practice, if $q$ is $n$ bits then typically $\\lambda \\leq n$, so it suffices to sample $2n$ bits and reduce mod $q$. For example, the ed25519 nonce generation proceeds by reducing the output of HMAC-SHA512 modulo the 255-bit order of the curve.\nStatistical Distance # The statistical distance, also known as the \u0026ldquo;total variational distance\u0026rdquo; of the distribution of a random variable $X$ from that of another random variable $Y$ both with support $[q]$ is defined as $$ \\Delta(X,Y) = \\frac{1}{2}\\sum_{a = 0}^q |\\Pr[X = a] - \\Pr[Y = a]| $$\nThe statistical distance gives an upper bound on the success probability of any adversary at distinguishing two distributions. For any function $A: [q] \\rightarrow \\{0,1\\}$:\n$$ |\\Pr[A(X) = 1] - \\Pr[A(Y) = 1]| \\leq \\Delta(X, Y) $$ and in fact if $X_1, \\dots X_n$ are identically and independent distributed and similarly for $Y_1, \\dots, Y_n$ then\n$$ |\\Pr[A(X_1, \\dots, X_n) = 1] - \\Pr[A(Y_1, \\dots, Y_n) = 1]| \\leq n \\cdot \\Delta(X_1, Y_1) $$\nLetting $U$ be the uniform distribution over $[q]$, define $S(X) = \\Delta(X, U)$. It follows that if $S(X) \\leq 2^{-\\lambda}$ then no adversary can distinguish $X$ from the uniform distribution with probability more than $1/2$ using fewer than $2^{\\lambda - 1}$ samples.\nStatistical distance of wide modular reduction # Let $X_{n}$ denote random variable resulting from sampling uniformly in $[2^n]$ and reducing modulo $q$. Let $U$ be a random variable uniformly distributed over $q$. We can compute the statistical distance of $X_n$ from $U_{q}$ explicitly: Let $2^n = k\\cdot q + r$ for $0 \\leq r \u0026lt; q$. Then for all $a \u0026lt; r$\n$$ \\Pr[X = a] = \\frac{k + 1}{2^n} = \\frac{\\frac{2^n - r}{q} + 1}{2^n} = \\frac{2^n - r + q}{2^n q} = \\frac{1}{q} + \\frac{q - r}{2^n q} $$\nand so $$ |\\Pr[X = a] - 1/q| = \\frac{q - r}{2^n q} $$ while a similar computation for $a \\geq r$ gives $$ |\\Pr[X = a] - 1/q| = \\left|\\frac{k}{2^n} - \\frac{1}{q}\\right| = \\frac{r}{2^n q} $$\nand thus in total $$ S(X) = \\frac{1}{2}\\sum_{a = 0}^{r-1} \\frac{q - r}{2^n q} + \\sum_{a = r}^{q-1} \\frac{r}{2^n q} = \\frac{r}{2} \\cdot \\frac{q - r}{2^n q} + \\frac{q - r}{2} \\cdot\\frac{r}{2^n q} = \\frac{r(q - r)}{2^n q} $$\nThis formula tells us some interesting things about modulo bias:\nWhen $q$ is a power of 2 less than $2^n$ then $r = 0$, so there is no modulo bias In the worst case, when $r = q/2$, $S(X) = q/2^{n+2}$. If we choose \u0026ldquo;just enough\u0026rdquo; bits, such that $2^{n-1} \u0026lt; q \u0026lt; 2^n$, then $S(X) \\geq 1 / 8$. This is a very substantial advantage, enough to clearly distinguish from uniform after only a few trials. If we $\\lambda$ is a security parameter and $q$ is an $n$-bit number then by selecting $n + \\lambda$ bits we get a statistical distance of at most $\\frac{1}{2^{\\lambda + 2}}$. Rejection sampling # Suppose we know how to sample from a set $S$ and would like to sample from an arbitrary subset $T\\subseteq S$. To do this, we need to check membership in $T$ and perform rejection sampling. In a loop:\nsample element $e \\in S$. if $e \\in T$, return $e$, otherwise repeat step 1. On average this requires looping $|S|/|T|$ times. If $|S| \\leq 2|T|$, the probability that we will need to sample more than $k$ elements from $S$ is at most $2^{-k}$. Thus as long as $|S|$ is not too much bigger than $|T|$, the rejection sampling algorithm almost always terminates in only a few iterations.\nUniform sampling in $\\zqs$ # Elements of $\\zqs$ are natural numbers $e$ such that $e \\in [q]$ and $\\gcd(e, q) = 1$. To sample these elements uniformly we need to perform rejection sampling. In a loop,\nSample element $e \\in [q]$. If $\\gcd(e, q) = 1$ return $e$, otherwise repeat step 1. 1 2 3 4 5 6 7 8 import secrets import math def sample_Zqstar(): while True: e = secrets.randbelow(q) if math.gcd(e, q) == 1: return e Note: Since $\\gcd(0, q)$ is never 1, we could also sample $e$ from the set $\\rangeone{q}$. "},{"id":1,"href":"/docs/zkdocs/","title":"Introduction","section":"Docs","content":" Introduction # Zero-knowledge protocols # ZKDocs provides comprehensive, detailed, and interactive documentation on zero-knowledge proof systems and related primitives.\nAt Trail of Bits, we audit many implementations of non-standardized cryptographic protocols and often find the same issues. As we discovered more instances of these bugs, we wanted to find a way to prevent them in the future. Unfortunately, for these protocols, the burden is on the developers to figure out all of the low-level implementation details and security pitfalls.\nWe hope that ZKDocs can fill in this gap and benefit the larger cryptography community.\nComprehensive # We aim to be both self-contained and comprehensive in the topics related to zero-knowledge proof systems, from descriptions of simple systems like Schnorrâ€™s identification protocol, to complex proof systems like Paillier-Blum modulus. We also cover cryptographic primitives such as: random sampling, Fiat-Shamir transformation, and Shamir\u0026rsquo;s Secret Sharing. Detailed # We describe each protocol in great detail, including all necessary setup, sanity-checks, auxiliary algorithms, further references, and potential security pitfalls with their associated severity. Interactive # The protocol descriptions are interactive, letting you modify variable names. This allows you to match the variable names in ZKdocs\u0026rsquo; specification to the variable names in your code, making it easier to find bugs and missing assertions.\nInteractivity features:\nClick on $\\varX$ to highlight the variable across the document. Try it! Type or paste with $\\varX$ highlighted to edit $\\varX$\u0026rsquo;s name. Press Enter or Escape to stop editing. Press the Reset variables names button to reset the names of all variables on the current page (variable names are independent across different pages) Contribute # We will continue to add more proof systems like Range proofs, STARK, and Bulletproofs.\nFeel free to open issues and suggest new protocols that you would like to see added in ZKDocs.\n"},{"id":2,"href":"/docs/zkdocs/notation/","title":"Notation \u0026 Definitions","section":"Introduction","content":" Notation and Definitions # This page is a glossary for notation and concepts present in the documentation.\nSets, Groups, and Special Functions # $\\mathbb{Z}$ is the set of integers, $\\{\\ldots, -2, -1, 0, 1, 2, \\ldots\\}$. $\\naturals$ is the set of integers greater of equal than 0, $\\{0, 1, 2, \\ldots\\}$. $\\range{b}$ is the finite set of integers $\\{0, \\ldots, b-1\\}$. $\\gcd(n, m)$ is the nonnegative greatest common divisor of integers $n$ and $m$; when $\\gcd(n, m) = 1$, $n$ and $m$ are said to be coprime. $\\z{n}$ are the integers modulo $n$, a set associated with the equivalence classes of integers $\\{0, 1, \\ldots, n-1\\}$. $\\zns{n}$ is the multiplicative group of integers modulo $n$: an element $e$ from $\\z{n}$ is in $\\zns{n}$ iff $\\gcd(e, n) = 1$, that is $\\zns{n} = \\{e \\in \\z{n}: \\gcd(e, n) = 1\\}$. When $n$ is prime, then $\\zns{n} = \\{1, \\ldots, n-1\\}$. $\\field{p}$ is the finite field of order $p$; when $p$ is a prime number, these are the integers modulo $p$, $\\z{p}$; when $p$ is a prime power $q^k$, these are Galois fields. $\\varphi(n)$ is Euler\u0026rsquo;s totient function; for $n\\geq 1$, it is the number of integers in $\\{1,\\ldots, n\\}$ coprime with $n.$ $|S|$ is the order of a set $S$, i.e., its number of elements. For example, $|\\zns{n}| = \\varphi(n)$, and for a prime $n$, $|\\zns{n}| = n-1$. Vectors # $\\vec{a} \\in \\z{q}^n$ is a vector $(a_1,\\dots,a_n)$ with $a_i \\in \\z{q}$ for all $i$. $c \\cdot \\vec{a}$ denotes the scalar product $(c \\cdot a_1,\\dots,c \\cdot a_n)$. $\\ip{\\vec{a}}{\\vec{b}}$ denotes the inner product $\\sum_{i=1}^n a_i \\cdot b_i$. Number-theory # $J(w, n)\\in \\{-1, 0, 1\\}$ is the Jacobi symbol of $w$ modulo $n$, only defined for positive and odd $n$. $J_n$ is the set of elements of $\\zns{n}$ with Jacobi symbol $1$. $QR_n$ is the set of quadratic residues modulo $n$, which are elements that have a square-root, i.e., $QR_n = \\{e \\in \\z{n} : \\exists r . r^2 = e \\mod n\\}$. Sampling # In protocol specifications, we will often need to uniformly sample elements from sets. We will use the following notation:\n$\\sampleGeneric{x}{X}$, where $x$ is uniformly sampled from the set $X$. Consider reading the section on Random Sampling to learn how to correctly sample a number uniformly using rejection sampling, avoiding the modulo-bias issue.\nAssertions # We will use assertions in protocol descriptions. When the assertions do not hold, the protocol must abort to avoid leaking secret information.\n$a \\equalQ b$, requires $a=b$, and aborts otherwise $a \\gQ b$, requires $a\u0026gt;b$, and aborts otherwise $a \\inQ S$, requires that $a$ is in the set $S$, and aborts otherwise. Implementations of number-theoretic algorithms # In general, we highly recommend the Handbook of Applied Cryptography, which has detailed descriptions of most algorithms.\nHash Functions # $\\hash{\\cdot}$ is a cryptographically secure domain-separated hash function. $\\hashbit{\\cdot}{k}$ is a cryptographically secure domain-separated hash function with specific output-size of $k$-bits. Find more details on the particular hash functions in Nothing-up-my-sleeve constructions\n"},{"id":3,"href":"/docs/zkdocs/zero-knowledge-protocols/schnorr/","title":"Schnorr's identification protocol","section":"Zero-knowledge protocols","content":" Schnorr\u0026rsquo;s identification protocol # Schnorr\u0026rsquo;s identification protocol is the simplest example of a zero-knowledge protocol. With it, $\\varprover$ can convince $\\varverifier$ that they know the discrete logarithm $\\varx$ of some value $\\varh = \\varg^\\varx$, without revealing $\\varx$.\nGoal: $\\varprover$ convinces $\\varverifier$ that they know $\\varx$ such that $\\varh = \\varg^\\varx$. Public input: cyclic group $\\cgroup$ of prime order $\\varq$, a $\\cgroup$ generator $\\varg$ and $\\varh\\in \\cgroup$. Private input: $\\varprover$ knows secret $\\varx\\in\\zq$ such that $\\varh = \\varg^\\varx$. Multiplicative notation Interactive protocol # The Schnorr interactive identification protocol\n$$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\samplezqs{\\varr}} \\alicework{\\varu = \\varg^\\varr} \\alicebob{}{\\varu}{} \\bobwork{\\schnorrvalidate(\\varu, \\varh)} \\bobseparator \\bobwork{\\sample{\\varc}} \\bobalice{}{\\varc}{} \\alicework{\\varz = \\varr + \\varx\\cdot \\varc} \\alicebob{}{\\varz}{} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\varg^{\\varz} \\equalQ \\varu \\cdot \\varh^\\varc } \\end{array} $$\nNon-interactive protocol # We can transform this identification scheme into a non-interactive protocol using the Fiat-Shamir heuristic. Here, the prover creates the random challenge $c$ hashing all public values $\\{\\varg, \\varq, \\varh, \\varu\\}$.\n$$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\samplezqs{\\varr}} \\alicework{\\varu = \\varg^\\varr} \\alicework{\\varc = \\hash{\\varg, \\varq, \\varh, \\varu}} \\alicework{\\varz = \\varr + \\varx\\cdot \\varc} \\alicebob{}{\\varu, \\varc, \\varz}{} \\bobwork{\\schnorrvalidate(\\varu, \\varh)} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\varc \\equalQ \\hash{\\varg, \\varq, \\varh, \\varu}} \\bobwork{\\varg^\\varz \\equalQ \\varu \\cdot \\varh ^\\varc } \\end{array} $$\nAdditive notation Interactive protocol # The Schnorr interactive identification protocol\n$$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\samplezqs{\\varr}} \\alicework{\\varu = \\varr\\cdot\\varg} \\alicebob{}{\\varu}{} \\bobwork{\\schnorrvalidate(\\varu, \\varh)} \\bobseparator \\bobwork{\\sample{\\varc}} \\bobalice{}{\\varc}{} \\alicework{\\varz = \\varr + \\varx\\cdot \\varc} \\alicebob{}{\\varz}{} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\varg^{\\varz} \\equalQ \\varu \\cdot \\varh^\\varc } \\end{array} $$\nNon-interactive protocol # We can transform this identification scheme into a non-interactive protocol using the Fiat-Shamir heuristic. Here, the prover creates the random challenge $c$ hashing all public values $\\{\\varg, \\varq, \\varh, \\varu\\}$.\n$$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\samplezqs{\\varr}} \\alicework{\\varu = \\varr\\cdot \\varg} \\alicework{\\varc = \\hash{\\varg, \\varq, \\varh, \\varu}} \\alicework{\\varz = \\varr + \\varx\\cdot \\varc} \\alicebob{}{\\varu, \\varc, \\varz}{} \\bobwork{\\schnorrvalidate(\\varu, \\varh)} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\varc \\equalQ \\hash{\\varg, \\varq, \\varh, \\varu}} \\bobwork{\\varz \\cdot \\varg \\equalQ \\varu + \\varc\\cdot\\varh} \\end{array} $$\nwhere $\\schnorrvalidate(\\varu, \\varh)$ aborts if any of the following conditions are not met:\n$\\varu, \\varh \\neq 0 \\text{ (point at infinity for EC groups)}$ and $\\varu, \\varh \\inQ \\cgroup\\text{ (on curve check for EC groups)}$. Security pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Verifier trusts prover: On the verification check, the verifier uses $g$ and $q$ provided with the proof instead of using publicly known values. On the NI version, the verifier assumes that the hash $\\varc$ is correctly computed and does not compute it themself. Both are high severity issues since $\\varprover$ can forge proofs. Weak Fiat-Shamir transformation: In the non-interactive protocol, it is a common occurrence that some parameters are missing on the hash computation $\\hash{\\varg, \\varq, \\varh, \\varu}$: $\\varh$ or $\\varu$ missing: high severity issue. Read Fiat-Shamir transformation for more details. $\\varg$ or $\\varq$ missing: usually no issue, but it might be one if the Verifier uses these parameters directly from the proof structure. This way, the prover can provide bad generators or orders to forge the proof. Weak randomness: Bad randomness may cause the secret $\\varx$ to leak. If $\\varr$ is reused twice with two different interactive challenges, or different data on the non-interactive version then $$ \\frac{\\varz - \\varz\u0026rsquo;}{\\varc-\\varc\u0026rsquo;} = \\frac{\\varr -\\varr + \\varx\\cdot(\\varc - \\varc\u0026rsquo;)}{\\varc-\\varc\u0026rsquo;} = \\varx $$ Replay attacks: After a non-interactive proof is public, it will always be valid and anyone could pretend to know the secret value. To prevent this, consider adding the ID of both the prover and the verifier inside of the Fiat-Shamir hash computation. Security assumptions # Hash function: The hash function should be either TupleHash or SHA-256 where each input is domain separated with a unique string together with the length of each element. Hardness of the discrete logarithm: The order of the cyclic group $\\cgroup$ should be at least $\\varq\u0026gt;2^{K}$ where $K=256$, for a generic group $\\cgroup$. If $\\cgroup$ is a (prime-order) subgroup of $\\zps$, then $p$ should be greater than $2^{\\kappa}$ for $\\kappa=3072$ to avoid subexponential attacks based on the extra structure of $\\zps$. Note that this requires $p - 1 = q\\cdot r$ with some potentially composite number $r$. Refer to table 2 (pp. 54-55) of the NIST recommendations for an overview of different bit security levels for finite field discrete logarithms. "},{"id":4,"href":"/docs/zkdocs/zero-knowledge-protocols/schnorr-variants/","title":"Variants of Schnorr's identification protocol","section":"Zero-knowledge protocols","content":" Variants of Schnorr\u0026rsquo;s identification protocol # All variants of Schnorr\u0026rsquo;s protocol prove the knowledge of an $\\varx$ such that $\\varh = \\varg^\\varx$ for a public $\\varh$.\nThe differences are tradeoffs between the size of the proof statements and a more costly proof verification, and smaller communication overhead.\nGoal: $\\varprover$ convinces $\\varverifier$ that they know $\\varx$ such that $\\varh = \\varg^\\varx$ Public input: cyclic group $\\cgroup$ of prime order $\\varq$, a $\\cgroup$ generator $\\varg$ and $\\varh\\in \\cgroup$. Private input: $\\varprover$ knows secret $\\varx\\in\\zq$ such that $\\varh = \\varg^\\varx$. We present all variants in their non-interactive version.\nNon-interactive protocols # Original # $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleNs{\\varr}{\\varq}} \\alicework{\\varu = \\varg^\\varr} \\alicework{\\varc = \\hash{\\varg, \\varq, \\varh, \\varu}} \\alicework{\\varz = \\varr + \\varx\\cdot \\varc} \\alicebob{}{\\varu, \\varc, \\varz}{} \\bobwork{\\schnorrvalidate(\\varu, \\varh)} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\varc \\equalQ \\hash{\\varg, \\varq, \\varh, \\varu}} \\bobwork{\\varg^\\varz \\equalQ \\varu \\cdot \\varh ^\\varc } \\end{array} $$ Slim Original # In this variant, the prover does not send the value of $\\varc$ which has to be computed by the verifier. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleNs{\\varr}{\\varq}} \\alicework{\\varu = \\varg^\\varr} \\alicework{\\varc = \\hash{\\varg, \\varq, \\varh, \\varu}} \\alicework{\\varz = \\varr + \\varx\\cdot \\varc} \\alicebob{}{\\varu, \\varz}{} \\bobwork{\\schnorrvalidate(\\varu, \\varh)} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\bar{\\varc} = \\hash{\\varg, \\varq, \\varh, \\varu}} \\bobwork{\\varg^\\varz \\equalQ \\varu \\cdot \\varh ^\\overline{\\varc} } \\end{array} $$ Subtract # In this variant, the prover uses a subtraction to compute the value of $\\varz$.\n$$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleNs{\\varr}{\\varq}} \\alicework{\\varu = \\varg^\\varr} \\alicework{\\varc = \\hash{\\varg, \\varq, \\varh, \\varu}} \\alicework{\\varz = \\varr - \\varx\\cdot \\varc} \\alicebob{}{\\varu, \\varc, \\varz}{} \\bobwork{\\schnorrvalidate(\\varu, \\varh)} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\varc \\equalQ \\hash{\\varg, \\varq, \\varh, \\varu}} \\bobwork{\\varg^\\varz \\cdot \\varh ^\\varc \\equalQ \\varu } \\end{array} $$ Subtract + Derive # In this variant, the prover uses a subtraction to compute the value of $\\varz$ and does not send $\\varu$, which the verifier derives from the values they know.\n$$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleNs{\\varr}{\\varq}} \\alicework{\\varu = \\varg^\\varr} \\alicework{\\varc = \\hash{\\varg, \\varq, \\varh, \\varu}} \\alicework{\\varz = \\varr - \\varx\\cdot \\varc} \\alicebob{}{\\varc, \\varz}{} \\bobwork{\\schnorrvalidate(\\varh)} \\bobwork{\\varz \\neq 0 \\mod \\varq} \\bobseparator \\bobwork{\\bar{\\varu} = \\varg^\\varz \\cdot \\varh^\\varc} \\bobwork{\\bar{\\varc} = \\hash{\\varg, \\varq, \\varh, \\bar{\\varu}}} \\bobwork{\\varc \\equalQ \\bar{\\varc} } \\end{array} $$ where $\\schnorrvalidate(\\varh)$ aborts if any of the following conditions are not met:\n$\\varh \\neq 0 \\text{ (point at infinity for EC groups)}$ and $\\varh \\inQ \\cgroup\\text{ (on curve check for EC groups)}$. If called with two arguments, $\\schnorrvalidate(\\varu, \\varh)$ will abort if any of the following conditions are not met by either argument. Security pitfalls # These variants suffer from the same pitfalls as the original Schnorr scheme, with some adjustments when $\\varz$ is computed with a subtraction:\nVerifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Verifier trusts prover: $\\varverifier$ uses $g$ and $q$ provided in the proof instead of using publicly known values. When the $\\varprover$ sends $\\varc$, if the $\\varverifier$ assumes that the hash $\\varc$ is correctly computed and does not compute it themself. Both are high severity issues since $\\varprover$ can forge proofs. Weak Fiat-Shamir transformation: It is a common issue that some parameters are missing on the hash computation $\\hash{\\varg, \\varq, \\varh, \\varu}$: $\\varh$ or $\\varu$ missing: high severity issue. Read Fiat-Shamir transformation for more details. $\\varg$ or $\\varq$ missing: usually no issue, but it might be one if the Verifier uses these parameters directly from the proof structure. This way, the prover can provide bad generators or orders to forge the proof. Weak randomness: Bad randomness may cause the secret $\\varx$ to leak. If $\\varr$ is reused twice with two different non-interactive challenges then: $$ \\frac{\\varz - \\varz\u0026rsquo;}{\\varc-\\varc\u0026rsquo;} = \\frac{\\varr -\\varr + \\varx\\cdot(\\varc - \\varc\u0026rsquo;)}{\\varc-\\varc\u0026rsquo;} = \\varx \\enspace,$$ or when $\\varz$ is computed with a subtraction: $$ \\frac{\\varz - \\varz\u0026rsquo;}{\\varc\u0026rsquo;-\\varc} = \\frac{\\varr -\\varr + \\varx\\cdot(\\varc\u0026rsquo; - \\varc)}{\\varc\u0026rsquo;-\\varc} = \\varx \\enspace.$$ Replay attacks: After a non-interactive proof is public, it will always be valid and anyone could pretend to know the secret value. To prevent this, consider adding the ID of both the prover and the verifier inside of the Fiat-Shamir hash computation. "},{"id":5,"href":"/docs/zkdocs/zero-knowledge-protocols/","title":"Zero-knowledge protocols","section":"Introduction","content":" Zero-knowledge protocols # Here, we provide uniform, detailed descriptions to several zero-knowledge protocols. We include: necessary setup, security pitfalls and associated severity, safe parameter choices, and original references.\nSchnorr\u0026#39;s identification protocol The zero-knowledge proof for a discrete-logarithm in a prime modulo. Variants of Schnorr\u0026#39;s identification protocol Common variants of Schnorr\u0026rsquo;s protocol. Number is product of two primes Prove that a number is the product of two primes. We show two proofs of this: one for generic primes, and another, more efficient, when primes are congruent with 3 modulo 4. Girault\u0026#39;s identification protocol A statistical zero-knowledge proof for discrete-logarithm in a composite modulo. Short factoring proofs Proof of knowledge of the factorization of an integer. Inner Product Argument Proving the knowledge of vectors for a public inner product "},{"id":6,"href":"/docs/zkdocs/protocol-primitives/fiat-shamir/","title":"Fiat-Shamir transformation","section":"Protocol primitives","content":" Fiat-Shamir transformation # Overview # It turns out that in practice, most zero-knowledge proofs tend to have the same three-step structure:\nThe prover first generates some random value, the commitment, and sends it to the verifier. The verifier responds with a challenge value generated uniformly at random. The prover computes the final proof based on both the commitment and challenge. As you can tell, this structure is interactive, meaning that the prover requires a response from the verifier before they can complete their proof, which is not ideal for most applications. Fortunately, provers can avoid this by using the Fiat-Shamir heuristic (sometimes referred to as the Fiat-Shamir transformation), developed by Amos Fiat and Adi Shamir.\nThe idea behind the Fiat-Shamir transformation is that instead of having the verifier send a random challenge value to the prover, the prover can compute this value themselves by using a random function, such as a cryptographic hash function.\nExample: In the Schnorr protocol, we have an interactive and non-interactive version. In the interactive version, the prover sends their random commitment, $u = g^r$, and the verifier responds with a challenge value, $c$, that they generate uniformly at random. In the non-interactive version, the prover generates $c$ themselves by computing a hash over all of the public values, $c = \\hash{g,q,h,u}$. As we will discuss, the hash must include all of these values. If you\u0026rsquo;d like to read more about this, we\u0026rsquo;ve written a blog post describing how they work in more detail.\nWhat can go wrong? # This transformation may seem straightforward, but unfortunately, it tends to be very tricky in practice. In particular, the prover generates the random challenge value using a cryptographic hash function- but what are the inputs? It turns out that if you choose the wrong inputs, it usually means your proof system is broken. To see this, let\u0026rsquo;s look at Schnorr\u0026rsquo;s protocol as an example.\nBad example, NEVER DO THIS: Recall that in the Schnorr protocol, the prover generates their random commitment, $u = g^r$, computes the challenge value, $c$, and then computes the final proof $z = r + x\\cdot c$, where $x$ is the secret value corresponding to their public key, $h = g^x$. Let\u0026rsquo;s say the implementation is incorrect, and the challenge value, $c$, is not computed using the public key, $h$, and instead it\u0026rsquo;s computed as $c = \\hash{g,q,u}$. It turns out that malicious provers can now forge proofs by doing the following attack:\nSet the commitment value, $u$, to be some public key that you do not know the secret key for. Compute the challenge value $c = \\hash{g,q,u}$. Set the proof $z$ to be a random value, and then compute your public key to be $h = (\\frac{g^z}{u})^{\\frac{1}{c}}$ Send $u,c,z$ to the verifier. The verifier then performs their two checks: $c \\equalQ \\hash{g,q,u}$ and $g^z \\equalQ u\\cdot h^c$. The first check will pass as they are both the same, and the second check will pass because of how we constructed $z$, $u$, and $h$.\nSince we set $u$ to be some value we do not know the secret key for, we also will not know the secret key for $h$, which means we have forged our proof of knowledge.\nNote: This attack does not allow you to forge proofs for any public key, this only works for random public keys. This tends not to be problematic when Schnorr proofs as a proof of knowledge in the typical public-key model. However, this can be very problematic when these proofs are used in other scenarios, such as a cryptographic voting system.\nRecommendations # Rule of thumb # The exact inputs required for the hash function will be different for every zero-knowledge proof system. The general rule of thumb to follow is to include all of the public information and all elements in the proof transcript up until that point inside the hash function.\nIn the Schnorr protocol, the public information is the public key, $h$, and the parameters related to the group being used, $g$ and $q$, and the proof transcript also includes the commitment value, $u$, and so we include all of those values in our hash computation. For short factoring proof protocol, it\u0026rsquo;s a bit more complicated. The public information is the number the prover can factor, $N$, so this must be included. What about transcript values? In this scheme, the prover does a bit more work before computing the challenge compared to the Schnorr protocol. Specifically, they generate a random value ($r$), a series of values ($z_i$) using the nothing-up-my-sleeve construction, and then they compute $X = \\hash{\\bunchi{z_i^r \\mod N}}$ (this is not the Fiat-Shamir challenge). Since both the $X$ value and the set of $z_i$ values will be known to the verifier (i.e., they are part of the transcript), these must also be included in the hash computation. So, the correct challenge computation is $e = \\hash{N, \\bunchi{z_i}, X}$.\nNote: In the short factoring proof and in Girault\u0026rsquo;s scheme, the Fiat-Shamir challenge needs to additionally be of a specific bit-size. So, the correct computation is actually $e = \\hashbit{N, \\bunchi{z_i}, X}{k}$.\nRemember: Always include all public information and all transcript values. When in doubt, consult ZKDocs!\nPreventing replay attacks # Just like digital signatures, zero-knowledge proofs can also be susceptible to replay attacks. As is the case for other replay attacks, the severity of these replay attacks will be highly application and context-specific.\nIf you believe replay attacks could be severe for your application, you might be able to use the Fiat-Shamir transformation to protect yourself. Specifically, suppose your application has some notion of identity tied to each party (a unique party ID, for example). In that case, you should include the ID of the prover and the verifier inside of the Fiat-Shamir hash computation. Then, when the verifier verifies the proof, they should also check that the IDs used in the hash function match the ID of themself and the prover. This will prevent other malicious parties from replaying any proof that they did not produce themselves.\n"},{"id":7,"href":"/docs/zkdocs/zero-knowledge-protocols/product-primes/square-freeness/","title":"Number is square-free","section":"Number is product of two primes","content":" Number is square-free # To prove that a number is the product of two distinct primes, the first step is showing that the number is free of squares, i.e., that $\\varN$ is not of the form $\\varN = p^2 r$.\nThis proof shows in zero-knowledge \u0026ndash;without revealing the factors of the number\u0026ndash; that an element belongs to the set $$\\sqfree = \\{\\varN \\in \\naturals : \\text{there is no prime }p \\text{ such that }p^2|N \\}.$$\nThe protocol uses the fact that an honest prover can calculate $\\varN$-th roots of arbitrary numbers in $\\z{\\varN}$.\nGoal: $\\varprover$ convinces $\\varverifier$ that $\\varN$ is square-free without revealing its factorization. Public input: $\\varN\\in\\naturals$ Private input: $\\varprover$ knows the factorization of $\\varN = \\varp\\varq$ Security parameters: $\\alpha, \\kappa, m = \\ceil{\\kappa/ \\log_2 \\alpha}$ The protocol uses the constant $\\displaystyle\\Pi_\\alpha = \\prod_\\underset{p\\text{ prime}}{p\u0026lt;\\alpha} p$, the product of the primes smaller than $\\alpha$.\nWe assume that both parties agree with the security parameters $\\alpha, \\kappa$ and $m$ prior to the execution of the protocol.\nInteractive protocol (HVZK) # Security note: The protocol is zero-knowledge (does not reveal the factorization of $\\varN$) only when the verifier is honest and generates each $\\rhovar_i$ randomly. If the verifier choses these values maliciously they can recover the factorization of $\\varN$. If your attacker model takes this into consideration, use the non-interactive version. More details on Using HVZKP in the wrong context. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\bobwork{\\sampleN{\\rhovar_i}{\\varN}, \\text{ for }i=1,\\ldots,m} \\bobalice{}{\\{\\rhovar_i\\}_{i=1}^m}{} \\alicework{\\sigmavar_i = (\\rhovar_i)^{\\varN^{-1}\\mod \\varphi(\\varN)} \\mod \\varN,} \\alicework{\\text{ for }i=1,\\ldots,m} \\alicebob{}{\\{\\sigmavar_i\\}_{i=1}^m}{} \\bobwork{\\varN \\gQ 1} \\bobwork{\\gcd(\\varN, \\Pi_\\alpha) \\equalQ 1} \\bobwork{\\sigmavar_i \\mod \\varN \\gQ 0,} \\bobseparator \\bobwork{\\rhovar_i \\equalQ \\sigmavar_i^\\varN \\mod \\varN,} \\bobwork{\\text{ for }i=1,\\ldots,m} \\end{array} $$ Non-interactive protocol # The non-interactive version of the protocol replaces the verifier-side sampling of $\\rhovar_i$ elements and generates them using the Fiat-Shamir transformation. The participants only exchange one message, and there is no risk of leaking the factorization of $\\varN$ using maliciously chosen $\\rhovar_i$ values. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\rhovar_i = \\mathsf{gen}_\\rhovar(\\z{\\varN}, \\{\\varN,i\\})} \\alicework{\\sigmavar_i = (\\rhovar_i)^{\\varN^{-1}\\mod \\varphi(\\varN)} \\mod \\varN,} \\alicework{\\text{ for }i=1,\\ldots,m} \\alicebob{}{\\{\\sigmavar_i\\}_{i=1}^m}{} \\bobwork{\\varN \\gQ 1} \\bobwork{\\gcd(\\varN, \\Pi_\\alpha) \\equalQ 1} \\bobwork{\\sigmavar_i \\mod \\varN \\gQ 0 ,} \\bobseparator \\bobwork{\\rhovar_i = \\mathsf{gen}_\\rhovar(\\z{\\varN}, \\{\\varN,i\\})} \\bobwork{\\rhovar_i \\equalQ \\sigmavar_i^\\varN \\mod \\varN,} \\bobwork{\\text{ for }i=1,\\ldots,m} \\end{array} $$ Security pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Using the interactive protocol in a malicious verifier context: high severity issue which allows factoring $\\varN$; see Using HVZKP in the wrong context. Sampling $\\rhovar_i$ values uniformly and not using honest generation: high severity issue that allows $\\varprover$ to forge proofs by sampling $\\sampleSet{\\sigmavar_i}{\\z\\varN}$ and setting $\\rhovar_i = \\sigmavar_i^\\varN\\mod \\varN$. Verifier trusting prover on the non-interactive protocol: $\\varverifier$ uses $\\rhovar_i$ values provided by $\\varprover$ instead of generating them: this is a high severity issue since the prover can trivially forge proofs (e.g., by sending $\\rhovar_i=1, \\sigmavar_i=1$). $\\varverifier$ does not validate $\\sigmavar_i$ as valid values modulo $\\varN$ (between 0 and $\\varN -1)$: this allows replaying the same proof with different values with $\\sigmavar_i + k\\varN$. $\\varverifier$ does not compare the number of received $\\sigmavar_i$ with $m$: this can lead to the prover bypassing proof verification by sending an empty list, or fewer than $m$ elements. Replay attacks: After a non-interactive proof is public, it will always be valid and anyone could pretend to know how to prove the original statement. To prevent this, consider adding additional information to the generation of $\\rhovar_i$ values such as an ID of both the prover and the verifier, and a timestamp. The verifier must check the validity of these values when they verify the proof. Auxiliary functions - $\\mathsf{gen}_\\rhovar$ # Generate the $\\rhovar_i$ values with a standard nothing-up-my-sleeve construction in $\\z{\\varN}$, use binding parameters $\\{\\varN, i\\}$, bitsize of $|\\varN|$, and salt $\\mathsf{\u0026ldquo;squarefreeproof\u0026rdquo;}$. To prevent replay attacks consider including, in the binding parameters, ID\u0026rsquo;s unique to the prover and verifier. Choice of security parameters $\\alpha$, $\\kappa$ # The security of the protocol depends $\\alpha$ and $\\kappa$ which define the number of witnesses that $\\varprover$ has to give $\\varverifier$. The protocol achieves a statistical soundness error of $2^{-\\kappa}$, which means $\\varprover$ cannot cheat except with probability $2^{-\\kappa}$.\nParameter $\\alpha$ is tunable and controls proving and verification time. Higher $\\alpha$ values will generally decrease proving time and verification time, until some limit is reached and the verification time starts increasing.\nRecommended values for the security parameters are:\n$\\kappa = 128$ $\\alpha = 65537, 319567$ can be tried and the best performing one chosen. These values yield $m$ values of\n$m(\\kappa=128, \\alpha=65537) = 8$ and $m(\\kappa=128, \\alpha=319567) = 7$. "},{"id":8,"href":"/docs/zkdocs/security-of-zkps/","title":"Security of ZKPs","section":"Introduction","content":" Security of ZKPs and their implementations # Here we present several security issues with implementations of zero-knowledge protocols, Fiat-Shamir transformations, and what can happen when interactive zero-knowledge proof systems are used in the context of malicious adversaries.\nUsing HVZKP in the wrong context Potential attacks when honest verifier zero-knowledge proofs are used in the context of a malicious verifier. See also: # Fiat-Shamir transformation "},{"id":9,"href":"/docs/zkdocs/zero-knowledge-protocols/product-primes/","title":"Number is product of two primes","section":"Zero-knowledge protocols","content":" Product of primes # One way to prove that some number $\\varN$ is the product of two primes $\\varN = \\varp \\varq$ is by showing that:\n$\\varN$ is square-free $\\varN$ only has two divisors If we only showed that $\\varN$ is square-free, then it could be of the form $\\varN = \\varp \\varq \\varr$. On the other hand, if we only proved that $\\varN$ has two divisors, it could be of the form $\\varN = \\varp^2\\varq$.\nWhen the primes are congruent with $3 \\; \\mathsf{mod}\\; 4$, we can show that $\\varN$ is the product of two primes much more efficiently with the Paillier-Blum modulus proof.\nNumber is square-free Proves that a number is square-free. Two prime divisors Proves that a number has two prime divisors. Product of two primes Proves that a number is the product of two distinct primes: in parallel, run the square-freeness proof together with the two-prime-divisors proof. Paillier-Blum Modulus An efficient proof that shows a number is the product of two primes congruent with 3 mod 4. "},{"id":10,"href":"/docs/zkdocs/protocol-primitives/","title":"Protocol primitives","section":"Introduction","content":" Protocol primitives # In this section, we detail commonly used primitives in zero-knowledge protocols.\nRandom Sampling In this section, we describe how to uniformly sample from different groups. Fiat-Shamir transformation Here, we describe what the Fiat-Shamir transformation is, its goals, its pitfalls, and its different versions. Nothing-up-my-sleeve constructions Generic, honest, and deterministic method to sample elements. Shamir\u0026#39;s Secret Sharing Scheme An overview of Shamir\u0026rsquo;s Secret Sharing scheme and potential security pitfalls. Feldman\u0026#39;s Verifiable Secret Sharing A verifiable version of Shamir\u0026rsquo;s secret sharing scheme due to Feldman. Alternative versions of Shamir\u0026#39;s Secret Sharing scheme Secret sharing alternatives which do not hide the secret in the constant term of the polynomial. "},{"id":11,"href":"/docs/zkdocs/zero-knowledge-protocols/product-primes/two-prime-divisors/","title":"Two prime divisors","section":"Number is product of two primes","content":" Number has exactly two prime divisors # To prove that a number is the product of two distinct primes, one step is showing that the number only has two prime divisors, i.e., showing that $\\varN$ is not of the form $\\varN = pqr$.\nThis protocol allows to prove in zero-knowledge \u0026ndash;without revealing its factors\u0026ndash; that a number is in the set $$L_{ppp} = \\{\\varN \\in \\naturals : \\varN \\text{ is odd and has exactly two distinct prime divisors}\\}.$$\nGoal: $\\varprover$ convinces $\\varverifier$ that $\\varN$ only has two distinct prime divisors without revealing its factorization. Public input: $\\varN\\in\\naturals$ Private input: $\\varprover$ knows the factorization of $\\varN = \\varp\\varq$ Security parameters: $\\kappa, m = \\ceil{\\kappa \\cdot 32 \\cdot \\ln(2)}$ The protocol works because an honest prover can calculate square-roots of arbitrary numbers in $\\z{\\varN}$.\nBoth parties have to agree on the security parameter $\\kappa$ prior to the execution of the protocol.\nInteractive protocol # Security note: The protocol is zero-knowledge (does not reveal the factorization of $\\varN$) only when the verifier is honest and generates each $\\rhovar_i$ randomly. If the verifier choses these values maliciously they can recover the factorization of $\\varN$. If your attacker model takes this into consideration, use the non-interactive version. More details on Using HVZKP in the wrong context. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\bobwork{\\sampleSet{\\rhovar_i}{J_\\varN}, \\text{ for }i=1,\\ldots,m} \\bobalice{}{\\{\\rhovar_i\\}_{i=1}^m}{} \\alicework{\\sigmavar_i = \\begin{cases} \\sqrt{\\rhovar_i} \\mod \\varN \u0026\\text{ if }\\rhovar_i \\in QR_\\varN \\\\ 0 \u0026\\text{ otherwise} \\end{cases} } \\alicework{\\text{ for }i=1,\\ldots,m} \\alicebob{}{\\{\\sigmavar_i\\}_{i=1}^m}{} \\bobwork{\\varN \\gQ 1} \\bobwork{\\varN \\mod 2 \\equalQ 1} \\bobwork{\\mathsf{isPrime}(\\varN) \\equalQ false} \\bobwork{\\mathsf{isPrimePower}(\\varN) \\equalQ false} \\bobwork{\\gcd(\\varN, \\Pi_\\alpha) \\equalQ 1} \\bobseparator \\bobwork{|\\{\\sigmavar_i \\text{ for }i=1,\\ldots,m| \\sigmavar_i \\neq 0 \\mod \\varN\\}| \\gQ 3m/8} \\bobwork{\\text{if } \\sigmavar_i \\neq 0 \\mod \\varN \\text{ then }\\rhovar_i \\equalQ \\sigmavar_i^2 \\mod \\varN} \\end{array} $$ In this protocol we need to uniformly sample from the $J_\\varN$, the set of integers modulo $\\varN$ with Jacobi symbol $1$. The prover also needs to check membership of the $QR_\\varN$, the set of quadratic residues modulo $\\varN$. Both computations, the Jacobi symbol and quadratic residuosity, can be done efficiently.\nNon-interactive protocol # The non-interactive version of the protocol replaces the verifier-side sampling of $\\rhovar_i$ and generates them using the $\\mathsf{gen}_\\rhovar$ function. The participants only exchange one message and this proof can be used in the context of malicious verifiers. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\rhovar_i = \\mathsf{gen}_\\rhovar(J_\\varN, \\{\\varN,i, F\\})} \\alicework{\\sigmavar_i = \\begin{cases} \\sqrt{\\rhovar_i} \\mod \\varN \u0026\\text{ if }\\rhovar_i \\in QR_\\varN \\\\ 0 \u0026\\text{ otherwise} \\end{cases} } \\alicework{\\text{ for }i=1,\\ldots,m} \\alicebob{}{\\bunchi{\\sigmavar_i}, F}{} \\bobwork{\\varN \\gQ 1} \\bobwork{\\varN \\mod 2 \\equalQ 1} \\bobwork{\\mathsf{isPrime}(\\varN) \\equalQ false} \\bobwork{\\mathsf{isPrimePower}(\\varN) \\equalQ false} \\bobwork{\\gcd(\\varN, \\Pi_\\alpha) \\equalQ 1} \\bobseparator \\bobwork{\\rhovar_i = \\mathsf{gen}_\\rhovar(J_\\varN, \\{\\varN,i, F\\})} \\bobwork{|\\{\\sigmavar_i \\text{ for }i=1,\\ldots,m| \\sigmavar_i \\neq 0 \\mod \\varN\\}| \\gQ 3m/8} \\bobwork{\\text{if } \\sigmavar_i \\neq 0 \\mod \\varN \\text{ then }\\rhovar_i \\equalQ \\sigmavar_i^2 \\mod \\varN} \\end{array} $$ Security pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Using the interactive protocol in a malicious verifier context: high severity issue which allows factoring $\\varN$; see Using HVZKP in the wrong context. Sampling $\\rhovar_i$ values uniformly and not using honest generation: high severity issue, allows $\\varprover$ to forge proofs by sampling $\\sampleSet{\\sigmavar_i}{\\z\\varN}$ and setting $\\rhovar_i = \\sigmavar_i^2\\mod \\varN$. Failing to include a fresh value in $\\mathsf{gen}_\\rhovar$: potential high severity issue since this means that all proofs for the same $\\varN$ will have the same $\\rhovar_i$; if the prover uses a probabilistic algorithm to compute square-roots, he can leak two different square-roots of the same value, allowing an attacker to factor $\\varN$ using the same attack as Using HVZKP in the wrong context. If the square-root algorithm always returns the same square-root for a given $\\rhovar_i$ this is not an issue. Verifier trusting prover on the non-interactive protocol: $\\varverifier$ uses $\\rhovar_i$ values provided by $\\varprover$ instead of generating them: this is a high severity issue since the prover can trivially forge proofs (e.g., by sending $\\rhovar_i=1, \\sigmavar_i=1$). $\\varverifier$ does not validate $\\sigmavar_i$ as valid values modulo $\\varN$ (between 0 and $\\varN -1)$: this allows replaying the same proof with different values with $\\sigmavar_i + k\\varN$. $\\varverifier$ does not compare the number of received $\\sigmavar_i$ with $m$: this can lead to the prover bypassing proof verification by sending an empty list, or fewer than $m$ elements. Replay attacks: After a non-interactive proof is public, it will always be valid and anyone could pretend to know how to prove it. To prevent this, consider adding additional information to the hash function such as an ID of both the prover and the verifier and a timestamp. Choice of security parameters $\\kappa$ # The protocol uses the security parameter $\\kappa$ to determine the number of exchanged elements.\nFor different $\\kappa$ values, we obtain\n$m(\\kappa=64) = 1420$ $m(\\kappa=128) = 2840$ Honest parameter generation $\\mathsf{gen}_\\rhovar$ # Generate the $\\rhovar_i$ values with a standard nothing-up-my-sleeve construction in $J_{\\varN}$, use binding parameters $\\{\\varN, i, F\\}$, bitsize of $|\\varN|$, and salt $\\mathsf{\u0026ldquo;twoprimedivisorsproof\u0026rdquo;}$. To prevent replay attacks consider including, in the binding parameters, ID\u0026rsquo;s unique to the prover and verifier. Auxiliary algorithms # To calculate the Jacobi symbol use Algorithm 2.149 of the Handbook of Applied Cryptography.\nTo calculate square-roots modulo $\\varN$ use Algorithm 3.44 of the Handbook of Applied Cryptography.\nTo implement $\\mathsf{isPrimePower}$, a simple algorithm is here and also explained on page 3 of the AKS paper. Note 3.6 of the Handbook of Applied Cryptography also has a description.\nMost libraries will have a primality testing routine for the $\\mathsf{isPrime}$ function.\n"},{"id":12,"href":"/docs/zkdocs/protocol-primitives/nums/","title":"Nothing-up-my-sleeve constructions","section":"Protocol primitives","content":" Nothing-up-my-sleeve constructions # Protocols often require using public but random group elements or alternative generators. If these were simply randomly sampled, other participants could be suspicious that the party did not honestly generate them.\nTo generate the elements you require:\nmembership: know how to check membership in the sample space bit-size: know the bit-size of the elements binding parameters: the protocol\u0026rsquo;s public values other binding parameters like an index salt Example: In the Short factoring proofs non-interactive protocol, we need to generate values $\\varz_i \\in \\zns{\\varN}$. Our ingredients are:\nmembership: to check if an element $e$ is in $\\zns{\\varN}$, we check that $\\gcd(e, \\varN) = 1$ bit-size: the element bit-size will be $|\\varN|$ binding parameters: $\\varN$ and $i$ salt: the salt can be $\\mathsf{\u0026ldquo;shortfactoringproof\u0026rdquo;}$ The construction is generic: start a counter and sample an element with an extendible-output hash function over the binding parameters and the counter; if the generated element is in the sample space, we return it; otherwise, we increment the counter and sample again.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 DS = \u0026#39;|\u0026#39; # Rejection sampling using a counter and binding parameters of the protocol def gen_element(sample_space_predicate, bitsize, param_list, salt): counter = 0 while True: # elements to hash elements = param_list + [salt, counter] # add each element\u0026#39;s length to_hash = [len(s) + s for s in elements] # domain separated elements to_hash = DS + DS.join(to_hash) # generate bitsize element with extendible-output hash function e = hash_xof(to_hash, bitsize) # check that e is in sample_space if sample_space_predicate(e): return e # increment counter counter += 1 Hash function choice # The hash function used here must be an extendible-output function (XOF). These hash functions can generate an output of arbitrary length. We must use these functions since the elements we are sampling can have an arbitrary number of bits, and failing to achieve that size can cause security issues. An example is $\\mathsf{SHAKE256}$, which provides 256-bit security against collision attacks when at least 512 bits are sampled.\nAn alternative is using $\\mathsf{TupleHash}$ which does not require manually domain-separating the elements to be hashed.\n"},{"id":13,"href":"/docs/zkdocs/zero-knowledge-protocols/girault-identification/","title":"Girault's identification protocol","section":"Zero-knowledge protocols","content":" Girault\u0026rsquo;s identification protocol # This scheme is a zero-knowledge proof for a discrete logarithm, like Schnorr\u0026rsquo;s protocol, but over a composite modulus instead of a prime modulus.\nGoal: $\\varprover$ convinces $\\varverifier$ that they know $\\varx$ such that $\\varh = \\varg^{-\\varx} \\mod \\varN$ Public input: $\\varh, \\varN$ and a high order generator $\\varg\\in \\zns{\\varN}$ Private input: $\\varprover$ knows the secret $\\varx\\in \\range{S}$ Security parameters: The parameters $k, k\u0026rsquo;, S$ and $R = 2^{k+k\u0026rsquo; + |S|}$. Interactive protocol # Security note: The interactive identification protocol assumes an honest verifier and should not be used in the context of malicious verifiers. A malicious verifier can send $\\vare = R$ and recover the secret $\\varx$ by dividing $\\varz$ by $\\vare$. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\varh = \\varg^{-\\varx} \\mod \\varN} \\alicework{\\sampleRange{\\varr}{R}} \\alicework{\\varu = \\varg^\\varr \\mod \\varN} \\alicebob{}{\\varu}{} \\bobwork{\\sampleRange{\\vare}{2^k}} \\bobalice{}{\\vare}{} \\alicework{\\varz = \\varr + \\varx\\cdot \\vare \\in \\naturals} \\alicebob{}{\\varz}{} \\bobwork{\\varu \\neq 0 \\mod \\varN} \\bobwork{\\varh \\neq 0 \\mod \\varN} \\bobwork{\\varz \\neq 0 \\mod \\varN} \\bobseparator \\bobwork{\\varu \\equalQ \\varg^{\\varz} \\cdot \\varh^\\vare \\mod \\varN} \\end{array} $$ Non-interactive protocol # We obtain a non-interactive protocol using the Fiat-Shamir heuristic, where the prover creates the random $k$-bit challenge $\\vare$ using domain-separated hash function over the $\\{\\varg, \\varN, \\varh, \\varu\\}$ parameters. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\varh = \\varg^{-\\varx} \\mod \\varN} \\alicework{\\sampleRange{\\varr}{R}} \\alicework{\\varu = \\varg^\\varr \\mod \\varN} \\alicework{\\vare = \\hashbit{\\varg, \\varN, \\varh, \\varu}{k}} \\alicework{\\varz = \\varr + \\varx\\cdot \\vare \\in \\naturals} \\alicebob{}{\\varu, \\vare, \\varz}{} \\bobwork{\\varu \\neq 0 \\mod \\varN} \\bobwork{\\varh \\neq 0 \\mod \\varN} \\bobwork{\\varz \\neq 0 \\mod \\varN} \\bobseparator \\bobwork{\\vare \\equalQ \\hashbit{\\varg, \\varN, \\varh, \\varu}{k}} \\bobwork{\\varu \\equalQ \\varg^{\\varz} \\cdot \\varh^\\vare \\mod \\varN} \\end{array} $$ Security pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Parameter choice: Implementers must pay special attention to the choice of parameter values, in particular the relation between $2^k$ and $R$. If these were of similar size, since $\\varz$ is computed over the naturals, $\\varx$ would be approximately $\\lfloor \\varz/\\vare\\rfloor$. Using the interactive protocol in a malicious verifier context: high severity issue which allows recovering the secret $\\varx$; see Using HVZKP in the wrong context. Verifier trusting prover on the non-interactive protocol: $\\varverifier$ uses a $\\varg$ value provided by $\\varprover$ instead of using the standard generator: this is a high severity issue since the prover can trivially forge proofs (e.g., by sending $\\varu=0, \\varg=0$). $\\varverifier$ does not validate $\\varu,\\varh$ as valid elements of $\\zns{\\varN}$ (between 1 and $\\varN-1$ and with $\\gcd(k, \\varN) = 1$): this allows replaying the same proof with different values adding multiples of $\\varN$. Replay attacks: After a non-interactive proof is public, it will always be valid, and anyone could pretend to know how to prove the original statement. To prevent this, consider adding additional information to the computation of the hash function: values such as an ID unique to the prover and verifier, and a timestamp. The verifier must use these values and check their validity to verify the proof. Choice of parameter values # $|\\varN| = 2048$ $S = 2^{256}$ $k,k\u0026rsquo; = 128$ Auxiliary procedures # Hash function $\\hashbit{\\cdot}{k}$: this hash function should be domain-separated and have a specific output size of $k$-bits. Using $\\mathsf{TupleHash}$ satisfies these restrictions. "},{"id":14,"href":"/docs/zkdocs/zero-knowledge-protocols/product-primes/product-of-two-primes/","title":"Product of two primes","section":"Number is product of two primes","content":" Number is the product of two primes # To show that a number is the product of two distinct primes, we make use of the previous protocols to show that:\n$\\varN$ is square-free $\\varN$ only has two divisors Formally, we show that $\\varN$ is in the set $$L_{pp} = \\{N \\in \\naturals | N \\text{ is odd and is the product of two distinct primes}\\} = L_{ppp} \\cap \\sqfree.$$ For this, we run the protocols from Square-free and Two prime divisors in parallel for the same $N$.\nGoal: $\\varprover$ convinces $\\varverifier$ that $\\varN$ is the product of two distinct primes without revealing its factorization. Public input: $\\varN\\in\\naturals$ Private input: $\\varprover$ knows the factorization of $\\varN = \\varp\\varq$ Security parameters: $\\alpha, \\kappa, m_1 = \\ceil{\\kappa/ \\log_2 \\alpha}$, $m_2 = \\ceil{\\kappa \\cdot 32 \\cdot \\ln(2)}$ We only present the non-interactive version of this protocol, suitable to use in the context of malicious verifiers.\nNon-interactive protocol # $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\rhovar_i = \\mathsf{gen}_\\rhovar(\\z{\\varN}, \\{\\varN,i\\})} \\alicework{\\sigmavar_i = (\\rhovar_i)^{\\varN^{-1}\\mod \\varphi(\\varN)} \\mod \\varN,} \\alicework{\\text{ for }i=1,\\ldots,m_1} \\aliceseparator \\alicework{\\thetavar_i = \\mathsf{gen}_\\rhovar(J_\\varN, \\{\\varN, m_1 + i, F\\})} \\alicework{\\muvar_i = \\begin{cases} \\sqrt{\\thetavar_i} \\mod \\varN \u0026\\text{ if }\\thetavar_i \\in QR_\\varN \\\\ 0 \u0026\\text{ otherwise} \\end{cases} } \\alicework{\\text{ for }i=1,\\ldots,m_2} \\alicebob{}{\\{\\sigmavar_i\\}_{i=1}^{m_1}, \\{\\muvar_i\\}_{i=1}^{m_2}, F}{} \\bobwork{\\varN \\gQ 1} \\bobwork{\\varN \\mod 2 \\equalQ 1} \\bobwork{\\mathsf{isPrime}(\\varN) \\equalQ false} \\bobwork{\\mathsf{isPrimePower}(\\varN) \\equalQ false} \\bobwork{\\gcd(\\varN, \\Pi_\\alpha) \\equalQ 1} \\bobwork{\\sigmavar_i \\mod \\varN \\gQ 0,} \\bobseparator \\bobwork{\\rhovar_i = \\mathsf{gen}_\\rhovar(\\z{\\varN}, \\{\\varN,i\\})} \\bobwork{\\rhovar_i \\equalQ \\sigmavar_i^\\varN \\mod \\varN,} \\bobwork{\\text{ for }i=1,\\ldots,m_1} \\bobwork{\\thetavar_i = \\mathsf{gen}_\\rhovar(J_\\varN, \\{\\varN, m_1 + i, F\\})} \\bobwork{|\\{\\muvar_i \\text{ for }i=1,\\ldots,m| \\muvar_i \\neq 0 \\mod \\varN\\}| \\gQ 3m_2/8} \\bobwork{\\text{if } \\muvar_i \\neq 0 \\mod \\varN \\text{ then }\\thetavar_i \\equalQ \\muvar_i^2 \\mod \\varN} \\bobwork{\\text{ for }i=1,\\ldots,m_2} \\end{array} $$ Security parameters # $\\kappa = 128$ $m_1(\\kappa=128, \\alpha=65537) = 8$ $m_2(\\kappa=128) = 2840$ Security pitfalls # This protocol suffers from the same pitfalls as the Square-free and Two prime divisors protocols. We include them here for clarity:\nVerifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Sampling the $\\rhovar_i$ or $\\thetavar_i$ values uniformly and not using honest generation: high severity issue that allows $\\varprover$ to forge proofs by sampling $\\sampleSet{\\sigmavar_i,\\muvar_i}{\\z\\varN}$, and setting $\\rhovar_i = \\sigmavar_i^\\varN\\mod \\varN$ and $\\thetavar_i = \\muvar_i^2\\mod \\varN$ . Failing to include a fresh value in $\\mathsf{gen}_\\rhovar$ to generate $\\thetavar_i$: potential high severity issue since this means that all proofs for the same $\\varN$ will have the same $\\thetavar_i$ values; if the prover uses a probabilistic algorithm to compute square-roots, he can leak two different square-roots of the same value, allowing an attacker to factor $\\varN$ using the same attack as Using HVZKP in the wrong context. If the square-root algorithm always returns the same square-root for a given $\\rhovar_i$ this is not an issue. Verifier trusting prover on the non-interactive protocol: $\\varverifier$ uses $\\rhovar_i$ or $\\thetavar_i$ values provided by $\\varprover$ instead of generating them: this is a high severity issue since the prover can trivially forge proofs (e.g., by sending $\\rhovar_i=1, \\sigmavar_i=1$ and $\\thetavar_i = 1, \\muvar_i=1$). $\\varverifier$ does not validate $\\sigmavar_i$, $\\muvar_i$ as valid values modulo $\\varN$ (between 0 and $\\varN -1)$: this allows replaying the same proof with different values with $\\sigmavar_i + k\\varN$, $\\muvar_i + k\u0026rsquo;\\varN$. $\\varverifier$ does not compare the number of received $\\sigmavar_i$ with $m_1$ and $\\muvar_i$ with $m_2$: this can lead to the prover bypassing proof verification by sending an empty list, or fewer than $m_1$ or $m_2$ elements. Replay attacks: After a non-interactive proof is public, it will always be valid and anyone could pretend to know how to prove the original statement. To prevent this, consider adding additional information to the generation of $\\rhovar_i$ and $\\thetavar_i$ values such as an ID of both the prover and the verifier, and a timestamp. The verifier must check the validity of these values when they verify the proof. Performance considerations # For the desired security level of $\\kappa=128$, we need to generate 2840 $\\muvar_i$ elements. Because of this, this proof system can be very computationally expensive. If this dramatically affects the performance of your protocol, and your $\\varN$ is the product of two primes congruent with $3\\mod 4$, we recommend using an alternative proof system, the Paillier-Blum modulus proof.\nHonest parameter generation $\\mathsf{gen}_\\rhovar$ # Generate the $\\rhovar_i$ and $\\thetavar_i$ values with a standard nothing-up-my-sleeve construction: $\\rhovar_i$ in $\\z{\\varN}$, use binding parameters $\\{\\varN, i\\}$, bitsize of $|\\varN|$, and salt $\\mathsf{\u0026ldquo;productoftwoprimesproof\u0026rdquo;}$. $\\thetavar_i$ in $J_{\\varN}$, use binding parameters $\\{\\varN, i, F\\}$, bitsize of $|\\varN|$, and salt $\\mathsf{\u0026ldquo;productoftwoprimesproof\u0026rdquo;}$. $F$ should be a fresh value unique to the current proof. To prevent replay attacks consider including, in the binding parameters, ID\u0026rsquo;s unique to the prover and verifier. Auxiliary algorithms # To calculate the Jacobi symbol use Algorithm 2.149 of the Handbook of Applied Cryptography.\nTo calculate square-roots modulo $\\varN$ use Algorithm 3.44 of the Handbook of Applied Cryptography.\nTo implement $\\mathsf{isPrimePower}$, a simple algorithm is here and also explained on page 3 of the AKS paper. Note 3.6 of the Handbook of Applied Cryptography also has a description.\nMost libraries will have a primality testing routine for the $\\mathsf{isPrime}$ function.\n"},{"id":15,"href":"/docs/zkdocs/security-of-zkps/when-to-use-hvzk/","title":"Using HVZKP in the wrong context","section":"Security of ZKPs","content":" Using HVZKP in the wrong context # Honest verifier zero-knowledge proofs (HVZKP) assume \u0026ndash;yes, you guessed it\u0026ndash; an honest verifier! This means that in the presence of malicious verifiers, non-interactive protocols should always be used. These also exchange fewer messages between prover and verifier.\nA malicious verifier can employ different attacks depending on the proof system. Here, we will present attacks for the Short factoring proofs and the Two prime divisors proof.\nThe case of the Short-Factoring-Proofs # Recall that in Short factoring proofs the prover shows that they know $\\varphi(\\varN)$ in the style of Girault\u0026rsquo;s scheme. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleRange{\\varr}{A}} \\alicework{\\varx_i = \\varz_i^\\varr \\mod \\varN} \\alicework{\\forb} \\alicebob{}{\\bunch{\\varx}}{} \\bobwork{\\sampleRange{\\vare}{B}} \\bobalice{}{\\vare}{} \\alicework{\\vary = \\varr + (\\varN - \\varphi(\\varN))\\cdot \\vare \\in \\naturals} \\alicebob{}{\\vary}{} \\bobwork{\\vary \\inQ \\range{A}} \\bobwork{\\varx_i \\equalQ \\varz_i^{\\vary- \\vare\\cdot\\varN} \\mod \\varN \\forb} \\end{array} $$ After the initial commit, the verifier responds with a challenge $e$ supposedly sampled from $\\range{B}$. However, being malicious, the verifier choses $\\vare=A$, the maximum value that $\\varr$ can be. So, that after receiving $\\vary = \\varr + (\\varN - \\varphi(\\varN))\\cdot \\vare$, they can compute $\\varN - \\vary//\\vare$ which will reveal $\\varphi(\\varN)$.\nThe case of the Two-Prime-Divisor proof # In the Two prime divisors proof, the prover has no way of checking if the verifier is trying to attack them. Recall the beginning of the protocol that the verifier chooses $\\rhovar_i$ values: $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\bobwork{\\sampleSet{\\rhovar_i}{J_\\varN}, \\text{ for }i=1,\\ldots,m} \\bobalice{}{\\{\\rhovar_i\\}_{i=1}^m}{} \\alicework{\\sigmavar_i = \\begin{cases} \\sqrt{\\rhovar_i} \\mod \\varN \u0026\\text{ if }\\rhovar_i \\in QR_\\varN \\\\ 0 \u0026\\text{ otherwise} \\end{cases} } \\alicework{\\text{ for }i=1,\\ldots,m} \\alicebob{}{\\{\\sigmavar_i\\}_{i=1}^m}{} \\end{array} $$ Then, the verifier computes the square-roots of these values! It is known that factoring and computing modular square-roots are equivalent [HOC - Fact 3.46].\nAn attacker can:\nselect random numbers $r_i$ send their square $r^2_i \\mod \\varN$ to the prover, The prover will compute their square roots, $\\sigma_i$ which can be different than $\\pm \\varr_i$ since there are four different square-roots modulo $\\varN = p q$. When $\\sigma_i\\neq \\pm \\varr_i$, computing $\\gcd (\\varN, \\sigma_i - r_i)$ will reveal one of the factors of $\\varN$. This is because\n$\\begin{align*} \\sigma_i^2 \u0026amp;\\equiv r_i^2 \\mod \\varN \\\\ (\\sigma_i^2 - r_i^2) \u0026amp;\\equiv 0 \\mod \\varN \\\\ (\\sigma_i - r_i)(\\sigma_i + r_i) \u0026amp;\\equiv 0 \\mod \\varN \\end{align*}$\n"},{"id":16,"href":"/docs/zkdocs/zero-knowledge-protocols/product-primes/paillier_blum_modulus/","title":"Paillier-Blum Modulus","section":"Number is product of two primes","content":" Paillier-Blum Modulus # This protocol allows the prover to show that a public modulus is the product of two $3 \\; \\mathsf{mod}\\; 4$ prime numbers. Since safe-primes \u0026ndash; primes of the form $p = 2q + 1$ where $q$ is also prime \u0026ndash; are congruent with $3\\; \\mathsf{mod}\\; 4$, this proof system can be used in those cases. Similar to the proof for Product of two primes, this system also uses the proof of Square freeness. This proof system is also much more efficient than the one for the Product of two primes.\nGoal: $\\varprover$ convinces $\\varverifier$ that $\\varN$ is the product of two primes congruent with $3\\; \\mathsf{mod}\\; 4$, and that $\\gcd(\\varN, \\varphi(\\varN)) = 1$, without revealing its factorization. Public input: modulus $\\varN$ Private input: $\\varprover$ knows $p,q$ such that $\\varN = p q$. These are primes congruent with $3\\; \\mathsf{mod}\\; 4$. Security parameters: $m$ to achieve a cheating probability of $2^{-m}$ Interactive protocol # Security note: The protocol is zero-knowledge (does not reveal the factorization of $\\varN$) only when the verifier is honest and randomly generates each $\\vary_i$. If the verifier chooses these values maliciously, they can recover the factorization of $\\varN$. If your attacker model considers this, use the non-interactive version. More details on Using HVZKP in the wrong context. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleN{\\varw}{\\varN} \\text{ with }J(\\varw, \\varN) = -1} \\alicebob{}{\\varw}{} \\bobwork{\\sampleNs{\\vary_i}{\\varN} } \\bobalice{}{\\bunch{\\vary}}{} \\alicework{\\varz_i = \\vary_i^{\\varN^{-1} \\mod \\varphi ( \\varN )}} \\alicework{\\varx_i = \\sqrt[4]{\\vary_i'} \\mod \\varN} \\alicework{\\text{where } \\vary_i' = (-1)^{\\vara_i} \\varw^{\\varb_i} \\vary_i \\in QR_\\varN} \\alicework{\\text{and } \\vara_i, \\varb_i \\in \\{0, 1\\}\\enspace\\;\\;} \\alicework{\\text{ for }i=1,\\ldots,m} \\alicebob{}{\\bunchi{(\\varx_i, \\vara_i, \\varb_i), \\varz_i}}{} \\bobwork{\\varN \\gQ 1} \\bobwork{\\varN \\mod 2 \\equalQ 1} \\bobwork{\\mathsf{isPrime}(\\varN) \\equalQ false} \\bobwork{\\varw \\mod \\varN \\gQ 0} \\bobwork{\\varx_i \\mod \\varN \\gQ 0} \\bobwork{\\varz_i \\mod \\varN \\gQ 0} \\bobwork{\\vara_i, \\varb_i \\inQ \\{0, 1\\} } \\bobwork{\\text{ for }i=1,\\ldots,m} \\bobseparator \\bobwork{ \\varz_i ^\\varN \\equalQ \\vary_i \\mod \\varN } \\bobwork{ \\varx_i ^4 \\equalQ (-1)^{\\vara_i} \\varw^{\\varb_i} \\vary_i \\mod \\varN } \\bobwork{\\text{ for }i=1,\\ldots,m} \\end{array} $$ Non-interactive protocol # The non-interactive version of the protocol replaces the verifier-side sampling of $\\vary_i$ and generates them using the $\\mathsf{gen}_\\vary$ function. The participants only exchange one message and this proof can be used in the context of malicious verifiers.\n$$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleN{\\varw}{\\varN} \\text{ with }J(\\varw, \\varN) = -1} \\alicework{\\vary_i = \\mathsf{gen}_\\vary(\\zns{\\varN}, \\{\\varN, \\varw, i\\})} \\alicework{\\varz_i = \\vary_i^{\\varN^{-1} \\mod \\varphi ( \\varN )}} \\alicework{\\varx_i = \\sqrt[4]{\\vary_i'} \\mod \\varN} \\alicework{\\text{where } \\vary_i' = (-1)^{\\vara_i} \\varw^{\\varb_i} \\vary_i \\in QR_\\varN} \\alicework{\\text{and } \\vara_i, \\varb_i \\in \\{0, 1\\}\\enspace\\;\\;} \\alicework{\\text{ for }i=1,\\ldots,m} \\alicebob{}{\\varw, \\bunchi{(\\varx_i, \\vara_i, \\varb_i), \\varz_i}}{} \\bobwork{\\varN \\gQ 1} \\bobwork{\\varN \\mod 2 \\equalQ 1} \\bobwork{\\mathsf{isPrime}(\\varN) \\equalQ false} \\bobwork{J(\\varw, \\varN) \\equalQ -1} \\bobwork{\\varw \\mod \\varN \\gQ 0} \\bobwork{\\varx_i \\mod \\varN \\gQ 0} \\bobwork{\\varz_i \\mod \\varN \\gQ 0} \\bobwork{\\vara_i, \\varb_i \\inQ \\{0, 1\\} } \\bobwork{\\text{ for }i=1,\\ldots,m} \\bobseparator \\bobwork{\\vary_i = \\mathsf{gen}_\\vary(\\zns{\\varN}, \\{\\varN, \\varw, i\\})} \\bobwork{ \\varz_i ^\\varN \\equalQ \\vary_i \\mod \\varN } \\bobwork{ \\varx_i ^4 \\equalQ (-1)^{\\vara_i} \\varw^{\\varb_i} \\vary_i \\mod \\varN } \\bobwork{\\text{ for }i=1,\\ldots,m} \\end{array} $$ Security pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Using the interactive protocol in a malicious verifier context: high severity issue which allows factoring the modulus $\\varN$; see Using HVZKP in the wrong context. Not checking that $\\varN \\mod 2 \\equalQ 1$ and $\\varN \\gQ 1$ before computing the Jacobi symbol $J(\\varw, \\varN)$: the Jacobi symbol is only defined when $\\varN$ is an odd positive integer. Failing to verify this might lead to a program panic, as in the Go library. Verifier trusting prover on the non-interactive protocol: $\\varverifier$ does not check that $J(\\varw, \\varN) = -1$: high severity issue since this allows $\\varprover$ to submit a proof forgery with $\\varw = 0$ and $\\varx_i = 0$. $\\varverifier$ uses $\\vary_i$ values provided by $\\varprover$ instead of generating them: high severity issue since the prover can trivially forge proofs (e.g., by sending $\\rhovar_i=1, \\sigmavar_i=1$). $\\varverifier$ does not validate $\\varw, \\varz_i, \\varx_i$ as valid values modulo $\\varN$ (between 0 and $\\varN -1)$: this allows replaying the same proof with different values with $\\varz_i + k\\varN$. $\\varverifier$ does not compare the number of received tuples $(\\varx_i, \\vara_i, \\varb_i), \\varz_i$ with $m$: this can lead to the prover bypassing proof verification by sending an empty list, or fewer than $m$ elements. Reusing the same $\\varw$ for further proofs of $\\varN$: reusing the same $\\varw$ value means that for a fixed $\\varN$, the $\\vary_i$ values will be the same; if the algorithm that computes the fourth-root is probabilistic, it can reveal different fourth-roots for the same value $\\vary_i\u0026rsquo;$, allowing an attacker to factor $\\varN$. Solve this in one of two ways: either add a fresh value to the parameters of $\\mathsf{gen}_\\vary$ and share it with $\\varverifier$, or ensure that you deterministically compute the fourth-roots. Replay attacks: After a non-interactive proof is public, it will always be valid, and anyone could pretend to know how to prove the original statement. To prevent this, consider adding additional information to the generation of $\\vary_i$ values, such as an ID of the prover and the verifier and a timestamp. The verifier must check the validity of these values when they verify the proof. Choice of security parameters # To achieve a safe security level, choose:\n$|\\varN| = 2048$ $m = 80$. Honest parameter generation $\\mathsf{gen}_\\vary$ # Generate the $\\vary_i$ values with a standard nothing-up-my-sleeve construction in $\\zns{\\varN}$, use binding parameters $\\{\\varN, \\varw, i\\}$, bitsize of $|\\varN|$, and salt $\\mathsf{\u0026ldquo;paillierblumproof\u0026rdquo;}$. To prevent replay attacks consider including, in the binding parameters, ID\u0026rsquo;s unique to the prover and verifier. Auxiliary algorithms # The function $J(\\varw, \\varN)$ is the Jacobi symbol of $\\varw$ modulo $\\varN$. To implement it use Algorithm 2.149 of the Handbook of Applied Cryptography. Compute modular fourth-roots using [HOC - Fact 2.160]: if $x$ is a quadratic residue modulo $\\varN = p q$ (and $p,q$ are $3\\mod 4$) then $\\sqrt[2]{x} = x^{(\\varphi + 4)/8} \\mod \\varN$, where $\\varphi = (p-1)\\cdot(q-1)$. Applying this computation twice yields the modular fourth-root: $\\sqrt[4]{x} = x^{((\\varphi + 4)/8)^2} \\mod \\varN$. Since the exponent does not depend on the input $x$, it can be computed once and for all. The prover has to check if an element is a quadratic residue modulo $\\varN$. To do this, use [HOC - Fact 2.137]: $x$ is a quadratic residue modulo $\\varN = pq$ if and only if it is a quadratic residue modulo $p$ and modulo $q$. A number $x$ is a quadratic residue modulo a prime $p$, if $x^{(p-1)/2} = 1$. Thus, $x$ is a quadratic residue modulo $\\varN = pq$ if and only if $x^{(p-1)/2} = 1$ and $x^{(q-1)/2} = 1$. Most libraries will have a primality testing routine for the $\\mathsf{isPrime}$ function. "},{"id":17,"href":"/docs/zkdocs/zero-knowledge-protocols/short-factoring-proofs/","title":"Short factoring proofs","section":"Zero-knowledge protocols","content":" Short factoring proofs # This system proves knowledge of the factorization of an integer $\\varN$. Unlike Product of two primes, this is not a proof that $\\varN$ has two prime factors, only that the prover knows its factorization! This protocol is not easy to implement securely, so we recommend special attention to sections Choice of security parameters and Security pitfalls.\nGoal: $\\varprover$ convinces $\\varverifier$ that they know the factorization of $\\varN$ without revealing it. Public input: An integer $\\varN$ Private input: $\\varprover$ knows the factorization of $\\varN =\\prod_i p_i^{e_i}$ Security parameters: The parameters $A, B, \\ell, m$, and $K$ all depend on $k$ and the bit-size of $\\varN$. Vanilla interactive protocol # Note: This version assumes that $\\varverifier$ is honest. A dishonest one would send $\\vare$ with similar size to $B$ and factor $\\varN$ using this attack. The following diagram shows one of the protocol\u0026rsquo;s $\\ell$ iterations. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleRange{\\varr}{A}} \\alicework{\\varz_i = \\mathsf{gen}_\\varz(\\zns{\\varN}, \\{\\varN, i\\})} \\alicework{\\varx_i = \\varz_i^\\varr \\mod \\varN} \\alicework{\\forb} \\alicebob{}{\\bunch{\\varx}, \\bunch{\\varz}}{} \\bobwork{\\sampleRange{\\vare}{B}} \\bobalice{}{\\vare}{} \\alicework{\\vary = \\varr + (\\varN - \\varphi(\\varN))\\cdot \\vare \\in \\naturals} \\alicebob{}{\\vary}{} \\bobwork{\\vary \\inQ \\range{A}} \\bobwork{\\varN \\gQ 1} \\bobseparator \\bobwork{\\varx_i \\equalQ \\varz_i^{\\vary- \\vare\\cdot\\varN} \\mod \\varN \\forb} \\end{array} $$ Improved interactive protocol # Note: This version assumes that $\\varverifier$ is honest. A dishonest one would send $\\vare$ with similar size to $B$ and factor $\\varN$ using this attack. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleRange{\\varr}{A}} \\alicework{\\varz_i = \\mathsf{gen}_\\varz(\\zns{\\varN}, \\{\\varN, i\\})} \\alicework{\\varX = \\hash{\\bunchi{\\varz_i^\\varr \\mod \\varN}}} \\alicebob{}{\\varX, \\bunch{\\varz}}{} \\bobwork{\\sampleRange{\\vare}{B}} \\bobalice{}{\\vare}{} \\alicework{\\vary = \\varr + (\\varN - \\varphi(\\varN))\\cdot \\vare \\in \\naturals} \\alicebob{}{\\vary}{} \\bobwork{\\vary \\inQ \\range{A}} \\bobwork{\\varN \\gQ 1} \\bobseparator \\bobwork{\\varX \\equalQ \\hash{\\bunchi{\\varz_i^{\\vary- \\vare\\cdot\\varN} \\mod \\varN}}} \\end{array} $$ Non-interactive protocol # We use the Fiat-Shamir heuristic, and the prover creates $\\vare$ using a $|B|$-bit sized hash function $\\hashbit{\\cdot}{|B|}$ and past public values. $$ \\begin{array}{c} \\work{\\varprover}{\\varverifier} \\alicework{\\sampleRange{\\varr}{A}} \\alicework{\\varz_i = \\mathsf{gen}_\\varz(\\zns{\\varN}, \\{\\varN, i\\})} \\alicework{\\varX = \\hash{\\bunchi{\\varz_i^\\varr \\mod \\varN}}} \\alicework{\\vare = \\hashbit{\\varN, \\bunch{\\varz},\\varX}{|B|}} \\alicework{\\vary = \\varr + (\\varN - \\varphi(\\varN))\\cdot \\vare \\in \\naturals} \\alicebob{}{\\vare, \\vary, \\varX}{} \\bobwork{\\vary \\inQ \\range{A}} \\bobwork{\\varN \\gQ 1} \\bobseparator \\bobwork{\\varz_i = \\mathsf{gen}_\\varz(\\zns{\\varN}, \\{\\varN, i\\})} \\bobwork{\\vare = \\hashbit{\\varN, \\bunch{\\varz},\\varX}{|B|}} \\bobwork{\\varX \\equalQ \\hash{\\bunchi{\\varz_i^{\\vary- \\vare\\cdot\\varN} \\mod \\varN}}} \\end{array} $$ Choice of security parameters # We detail the choice of security parameters based on the bit-size of $\\varN$:\n$k$ \u0026ndash; the security parameter; the cheating probability of the protocol is $2^{-k}$. Choose 80, 128 or 256. $B$ and $\\ell$ \u0026ndash; the size of the challenge space and number of iterations; $B$ and $\\ell$ should satisfy $\\ell\\cdot \\log B = \\theta(k)$, so chose $\\ell=1$ and $B=2^k$ in the non-interactive protocol. $A$ \u0026ndash; the size of the commit space; $A$ must be smaller than $\\varN$ and satisfy $(\\varN - \\varphi(\\varN) ) \\ell B \\ll A \u0026lt; \\varN$. If you are sure that public moduli are of a fixed size \u0026ndash;like $|\\varN| = 2048$\u0026ndash; chose $A=2^{|\\varN|}$. If the public modulus can have smaller bit-size but never below $|\\varN| - 4$, chose $A=2^{|\\varN| - 4}$. Security pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue.\nThe two interactive protocols assume an honest verifier. To use this protocol in the context of malicious verifiers, use the non-interactive version. See Using HVZKP in the wrong context.\nImplementers of this proof system need to carefully choose the security parameters since failing to do it correctly leaks $\\varphi(\\varN)$: Consider the example where $\\varN$ is 2048 bits, the product of two 1024 bit primes. $\\varprover$ computes over $\\naturals$ the value $$\\vary = \\varr + (\\varN - \\varphi(\\varN))\\cdot \\vare$$ where $\\sampleRange{\\varr}{A}$ and $\\sampleRange{\\vare}{B}$. If $A$ and $B$ have similar size then $\\frac{r}{e}$ will be very small and $\\varverifier$ can compute $$-\\left\\lfloor \\frac{\\vary}{e} \\right \\rfloor + \\varN = \\left\\lfloor \\frac{r}{e} \\right \\rfloor + \\varphi (\\varN) \\approx \\varphi(\\varN) \\enspace ,$$ recovering $\\varphi(\\varN)$.\nA variant of this attack happens when $|\\frac{r}{e}| \u0026lt; \\frac{|\\varphi(\\varN)|}{4}$: in this case, a quarter of the least significant bits of $\\varphi(\\varN)$ are unknown, but this still allows an attacker to factor $\\varN$ using Coppersmith\u0026rsquo;s attack.\nUsing high security parameters with small modulus allows proof forgery: the security parameters $A=2^{2048}$, $B=2^{128}$ are configured to be used with modulus of size 2048 but the verification routine does not check the size of the modulus. A dishonest prover can send a proof of knowledge for a 1024 modulus and $$\\vary = \\varN \\cdot \\vare$$ will still be in the set $\\range{A}$ since $\\varN\\cdot \\vare \u0026lt; 2^{1025 + 129} \u0026lt; 2^{2048} = A$.\nVerifier trusting prover on the non-interactive protocol: The $\\varverifier$ does not generate the $\\varz_i$ values and parses them from the proof without proper validation. The $\\varz_i$ values should be generated as described here. Failing to do so, and not checking that $\\varz_i\\in\\zns{\\varN}$, $\\varz_i \\mod \\varN \\not\\in \\{ -1 , 0, 1\\}$ leads to trivial proofs: when $\\varz_i \\equiv -1, 0, 1 \\mod \\varN$, all proofs are valid as long as $y\\in \\range{A}$.\nWeak Fiat-Shamir transformation: In the non-interactive protocol, it is a common mistake to not include all values in the hash computation $\\hashbit{\\varN, \\bunch{\\varz},\\varX}{|B|}$. If any of these values are not included in this computation, it could lead to a high severity issue where the prover can forge proofs. See Fiat-Shamir transformation for more details.\nReplay attacks: After a non-interactive proof is public, it will always be valid, and anyone could pretend to know how to prove it. To prevent this, consider adding additional information to the generation of the $\\varz$ values, such as an ID of the prover and the verifier and a timestamp. The verifier must check the validity of these values when they verify the proof. Honest parameter generation $\\mathsf{gen}_\\varz$ # Generate the $\\varz_i$ values with a standard nothing-up-my-sleeve construction in $\\zns{\\varN}$, use binding parameters $\\{\\varN, i\\}$, bitsize of $|\\varN|$, and salt $\\mathsf{\u0026ldquo;shortfactoringproofs\u0026rdquo;}$. To prevent replay attacks consider including, in the binding parameters, ID\u0026rsquo;s unique to the prover and verifier. Auxiliary procedures # Hash function $\\hashbit{\\cdot}{|B|}$: this hash function should be domain-separated and have a specific output size of $|B|$-bits. $\\mathsf{TupleHash}$ satisfies these restrictions. "},{"id":18,"href":"/docs/zkdocs/zero-knowledge-protocols/ipa/","title":"Inner Product Argument","section":"Zero-knowledge protocols","content":" Inner Product Argument # Overview of the Inner Product Argument # The inner product argument was introduced by Bootle et al. [BCCGP16] , and refined in Bulletproofs [BBBPWM18] and has the following structure.\nGoal: $\\varprover$ convinces $\\varverifier$ that they know vectors $\\veca$ and $\\vecb$ such that they have the inner product $\\ip{\\veca}{\\vecb} = \\varz$, and they open the commitment $\\varC_P = \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH}$. Public input: a cyclic additive group $\\cgroup$ of prime order $\\varq$ and $2n$ random $\\cgroup$ generators $\\vecG = (\\varG_1,\\dots,\\varG_n)$ and $\\vecH = (\\varH_1,\\dots,\\varH_n)$; vector commitment $\\varC_P \\in \\cgroup$ and scalar $\\varz \\in \\zq$.\nPrivate input: $\\varprover$ knows vectors $\\veca, \\vecb \\in \\zq^n$ that satisfy the vector commitment $\\varC_P = \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH}$, and have the inner product $\\varz = \\ip{\\veca}{\\vecb}$.\nThe Inner Product Argument # In this section, we build the inner product argument over four successive versions. But, first, we introduce vector commitments which underlie all versions.\nBackground: Vector Commitments # Pedersen commitments readily generalize from scalars to vectors of $n$ elements.\nAs before, start with a finite group $\\cgroup$ of prime order $q$, where $q$ is suitably large. Select $n$ random generators $\\vecG \\coloneqq (\\varG_1, \\varG_2,\\dots,\\varG_n)$ of $\\cgroup$ such that no discrete log relations are known between them. The parameters of the commitment scheme are $\\left(\\cgroup,\\varq,(\\varG_1,\\dots,\\varG_n)\\right)$.\nTo generate a commitment $\\varC \\in \\cgroup$ to a vector $\\vecs = (\\vars_1,\\dots,\\vars_n) \\in \\zq^n$ compute: $$ C \\coloneqq \\ip{\\vecs}{\\vecG} \\coloneqq \\vars_1\\varG_1 + \\vars_2\\varG_2 +\\cdots+ \\vars_n\\varG_n $$ To open the commitment, reveal the committed vector $\\vecs$.\nUpgrading to a hiding commitment. To achieve hiding in addition to binding, select another group element $\\varH$ with unknown discrete log relation, and during commitment, sample a new random value $\\sample{\\vart}$, and generate the commitment as $$ C(\\vecs, \\vart) \\coloneqq \\ip{\\vecs}{\\vecG} + t\\varH \\coloneqq \\vars_1\\varG_1 + \\vars_2\\varG_2 +\\cdots+ \\vars_n\\varG_n + \\vart\\varH $$ and to open the commitment, reveal the committed vector $\\vecs$ and the random value $t$. Version 1: A Simple Construction # Let\u0026rsquo;s start with a simple construction where the prover sends a commitment, and then immediately opens the commitment by sending over the secret vectors $\\veca$ and $\\vecb$ as the proof.\nWe will construct the commitment as a combination of commitments to vector $\\veca$, vector $\\vecb$, and their inner product $z = \\ip{\\veca}{\\vecb}$. First, the prover sends a commitment to the vectors: $$ \\varC_P \\coloneqq \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH}. $$ Then, the verifier samples a random group element $\\sampleCgroup{\\varU}$ and sends it the prover. The prover and the verifier independently compute the full commitment $$ \\varC \\coloneqq \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH} + \\ip{\\veca}{\\vecb} \\cdot \\varU. $$ Finally, the prover reveals the vectors $\\veca$ and $\\vecb$ and the verifier checks that they open the commitment. The resulting interactive protocol looks like the following:\n$$ \\begin{array}{lcl} \\uwork{\\varprover}{\\varverifier} \\alicework{\\varC_P \\coloneqq \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH}} \\alicebob{}{\\varC_P}{} \\bobworks{\\sampleCgroup{\\varU}} \\bobworks{\\varC' \\coloneqq \\varC_P + \\varz \\cdot \\varU} \\bobalice{}{\\varU}{} \\alicework{\\varC \\coloneqq \\varC_P + \\ip{\\veca}{\\vecb} \\cdot \\varU} \\alicebob{}{\\veca, \\vecb}{} \\bobwork{\\varC' \\equalQ \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH} + \\ip{\\veca}{\\vecb} \\cdot \\varU} \\end{array} $$ Since this always succeeds if $\\varz = \\ip{\\veca}{\\vecb}$, this construction has perfect completeness. Furthermore, since $\\varC$ is a binding commitment, it has computational soundness.\nComparison with [BCCGP16]. Rather than three separate commitments $A$, $B$, and $z$ for the vector $\\veca$, vector $\\vecb$, and their inner product $\\ip{\\veca}{\\vecb}$, following [BBBPWM18], we have one commitment $\\varC$ which combines all three. Comparison with [BBBPWM18]. Rather than let $\\varU$ be a fixed constant, it is sampled randomly by the verifier. As noted in Section 3.1 of [BGH19], this prevents the prover from picking $\\varC_{\\varP}$ conditioned on $\\varU$. This construction is not hiding. This construction does not hide the vectors $\\veca$ and $\\vecb$ since the prover reveals them to the verifier. This construction requires the verifier and prover to exchange two group elements ($\\varC_{\\varP}$ and $\\varU$) and two $n$-size vectors ($\\veca$ and $\\vecb$), giving total communication of size $2n + 2$. This is worse than the $O(1)$ communication required by similar commitment protocols like KZG commitments. Later versions will reduce this to $O(\\log n)$.\nVersion 2: Using Randomness to Halve Opening Communication # We are going to reduce the communication cost by reducing the size of the opening. In Version 1, we opened the commitments by providing the full-size vectors $\\veca$ and $\\vecb$. Here, we want to reduce this in half\u0026mdash;open the commitment with half-size $\\veca\u0026rsquo;$ and $\\vecb\u0026rsquo;$. The key insight is that, the prover and verifier can use verifier-generated randomness to jointly compute a new commitment $\\varC\u0026rsquo;$ which can be opened with half-size vectors $\\veca\u0026rsquo;$ and $\\vecb\u0026rsquo;$.\nFirst, let us split the vectors $\\veca$ and $\\vecb$ and generators $\\vecG$ and $\\vecH$ in half, giving us $$ \\begin{align} \\veca_L \u0026amp;\\coloneqq (\\vara_1,\\dots,\\vara_{n/2})\u0026amp; \\veca_R \u0026amp;\\coloneqq (\\vara_{n/2+1},\\dots,\\vara_{n})\\\\ \\vecb_L \u0026amp;\\coloneqq (\\varb_1,\\dots,\\varb_{n/2})\u0026amp; \\vecb_R \u0026amp;\\coloneqq (\\varb_{n/2+1},\\dots,\\varb_{n})\\\\ \\vecG_L \u0026amp;\\coloneqq (\\varG_1,\\dots,\\varG_{\\varn/2})\u0026amp; \\vecG_R \u0026amp;\\coloneqq (\\varG_{\\varn/2+1},\\dots,\\varG_{\\varn})\\\\ \\vecH_L \u0026amp;\\coloneqq (\\varH_1,\\dots,\\varH_{\\varn/2})\u0026amp; \\vecH_R \u0026amp;\\coloneqq (\\varH_{\\varn/2+1},\\dots,\\varH_{\\varn})\\\\ \\end{align} $$ Now, let\u0026rsquo;s make use of verifier-provided randomness $\\sample{\\varu}$, to define new half-size vectors and corresponding half-size generators $$ \\begin{align} \\veca\u0026rsquo; \u0026amp;\\coloneqq \\veca_L + \\varu^{-1} \\cdot \\veca_R\u0026amp; \\vecb\u0026rsquo; \u0026amp;\\coloneqq \\vecb_L + \\varu \\cdot \\vecb_R\\\\ \\vecG\u0026rsquo; \u0026amp;\\coloneqq \\vecG_L + \\varu \\cdot \\vecG_R\u0026amp; \\vecH\u0026rsquo; \u0026amp;\\coloneqq \\vecH_L + \\varu^{-1} \\cdot \\vecH_R \\end{align} $$\nOther combinations. There are other valid ways to compute the new half-size vectors. For instance, one can choose $$ \\begin{align} \\veca\u0026rsquo; \u0026amp;\\coloneqq \\varu \\cdot \\veca_L + \\varu^{-1} \\cdot \\veca_R\u0026amp; \\vecb\u0026rsquo; \u0026amp;\\coloneqq \\varu^{-1} \\cdot \\vecb_L + \\varu \\cdot \\vecb_R\\\\ \\vecG\u0026rsquo; \u0026amp;\\coloneqq \\varu^{-1} \\cdot \\vecG_L + \\varu \\cdot \\vecG_R\u0026amp; \\vecH\u0026rsquo; \u0026amp;\\coloneqq \\varu \\cdot \\vecH_L + \\varu^{-1} \\cdot \\vecH_R \\end{align} $$ and the same argument works. Using these, we can define a new commitment $\\varC\u0026rsquo; \\coloneqq \\ip{\\veca\u0026rsquo;}{\\vecG\u0026rsquo;} + \\ip{\\vecb\u0026rsquo;}{\\vecH\u0026rsquo;} + \\ip{\\veca\u0026rsquo;}{\\vecb\u0026rsquo;} \\cdot \\varU$ which can be opened with the half-size vectors $\\veca\u0026rsquo;$ and $\\vecb\u0026rsquo;$.\nNow all that remains is for the verifier and prover to jointly compute the new commitment $\\varC\u0026rsquo;$. They do this in three steps. First, the verifier locally generates some randomness and sends it to the prover. Second, the prover uses the verifier-provided randomness to compute some minimal structured information (the \u0026ldquo;cross-terms\u0026rdquo;) and sends them to the verifier. Finally, the verifier uses the cross-terms, along with their previously-generated randomness and the original commitment to compute the new commitment.\nBy the linearity of inner product, we can write the original commitment as $$ \\begin{align} \\varC \u0026amp;= \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH} + \\ip{\\veca}{\\vecb} \\cdot \\varU\\\\ \u0026amp;= \\ip{\\veca_L}{\\vecG_L} + \\ip{\\veca_R}{\\vecG_R} + \\ip{\\vecb_L}{\\vecH_L} + \\ip{\\vecb_R}{\\vecH_R} + \\ip{\\veca_L}{\\vecb_L} \\cdot \\varU + \\ip{\\veca_R}{\\vecb_R} \\cdot \\varU \\end{align} $$ Notice that this only has \u0026ldquo;straight-terms\u0026rdquo; (left terms paired with left terms and right terms paired with right terms), but to compute the new commitment $\\varC\u0026rsquo;$, the verifier also needs the cross-terms defined as: $$ \\begin{align} \\varL \u0026amp;\\coloneqq \\ip{\\veca_R}{\\vecG_L} + \\ip{\\vecb_L}{\\vecH_R} + \\ip{\\veca_R}{\\vecb_L} \\cdot \\varU\\\\ \\varR \u0026amp;\\coloneqq \\ip{\\veca_L}{\\vecG_R} + \\ip{\\vecb_R}{\\vecH_L} + \\ip{\\veca_L}{\\vecb_R} \\cdot \\varU \\end{align} $$ Indeed, these two cross-terms $\\varL$ and $\\varR$ and the original commitment $\\varC$ are sufficient for the verifier to compute the new commitment $$ \\begin{align} \\varC' \u0026amp;= \\ip{\\veca\u0026rsquo;}{\\vecG\u0026rsquo;} + \\ip{\\vecb\u0026rsquo;}{\\vecH\u0026rsquo;} + \\ip{\\veca\u0026rsquo;}{\\vecb\u0026rsquo;} \\cdot \\varU\\\\ \u0026amp;= (\\veca_L + \\varu^{-1} \\cdot \\veca_R)(\\vecG_L + \\varu \\cdot \\vecG_R) + (\\vecb_L + \\varu \\cdot \\vecb_R)(\\vecH_L + \\varu^{-1} \\cdot \\vecH_R) + \\left(\\veca_L + \\varu^{-1} \\cdot \\veca_R\\right)\\left(\\vecb_L + \\varu \\cdot \\vecb_R\\right) \\cdot \\varU\\\\ \u0026amp;= (\\veca_L + \\varu^{-1} \\cdot \\veca_R) \\cdot \\vecG_L + (\\varu \\cdot \\veca_L + \\veca_R) \\cdot \\vecG_R + (\\vecb_L + \\varu \\cdot \\vecb_R) \\cdot \\vecH_L + (\\varu^{-1} \\cdot \\vecb_L + \\vecb_R) \\cdot \\vecH_R + \\left(\\ip{\\veca_L}{\\vecb_L} + \\varu \\ip{\\veca_L}{\\vecb_R} + \\varu^{-1} \\ip{\\veca_R}{\\vecb_L} + \\ip{\\veca_R}{\\vecb_R}\\right) \\cdot \\varU\\\\ \u0026amp;= \\varu^{-1}(\\ip{\\veca_R}{\\vecG_L} + \\ip{\\vecb_L}{\\vecH_R} + \\ip{\\veca_R}{\\vecb_L} \\cdot \\varU) + (\\ip{\\veca_L}{\\vecG_L} + \\ip{\\veca_R}{\\vecG_R} + \\ip{\\vecb_L}{\\vecH_L} + \\ip{\\vecb_R}{\\vecH_R} + \\ip{\\veca_L}{\\vecb_L} \\cdot \\varU + \\ip{\\veca_R}{\\vecb_R} \\cdot \\varU) + \\varu (\\ip{\\veca_L}{\\vecG_R} + \\ip{\\vecb_R}{\\vecH_L} + \\ip{\\veca_L}{\\vecb_R} \\cdot \\varU)\\\\ \u0026amp;= \\varu^{-1} \\cdot \\varL + \\varC + \\varu \\cdot \\varR \\end{align} $$ Furthermore, at a high-level, this structure where the prover commits to $\\varC$ and the verifier randomly generates $\\varu$ prevents the prover from cheating and incorrectly computing $\\veca\u0026rsquo;$ and $\\vecb\u0026rsquo;$. See Appendix B of [BBBPWM18] for a formal proof.\nPutting it all together, we can define a new protocol as follows:\n$$ \\begin{array}{lcl} \\uwork{\\varprover}{\\varverifier} \\alicework{\\varC_P \\coloneqq \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH}} \\alicebob{}{\\varC_P}{} \\bobwork{\\sampleCgroup{\\varU}} \\bobalice{}{\\varU}{} \\work{\\varC \\coloneqq \\varC_P + \\ip{\\veca}{\\vecb} \\cdot \\varU}{\\varC \\coloneqq \\varC_P + \\varz \\cdot \\varU} \\aliceworks{\\varL \\coloneqq \\ip{\\veca_R}{\\vecG_L} + \\ip{\\vecb_L}{\\vecH_R} + \\ip{\\veca_R}{\\vecb_L} \\cdot \\varU} \\aliceworks{\\varR \\coloneqq \\ip{\\veca_L}{\\vecG_R} + \\ip{\\vecb_R}{\\vecH_L} + \\ip{\\veca_L}{\\vecb_R} \\cdot \\varU} \\alicebob{}{\\varL, \\varR}{} \\bobwork{\\sample{\\varu}} \\bobalice{}{\\varu}{} \\aliceworks{\\vecG' \\coloneqq \\vecG_L + \\varu \\cdot \\vecG_R} \\aliceworks{\\vecH' \\coloneqq \\vecH_L + \\varu^{-1} \\cdot \\vecH_R} \\aliceworks{\\veca' \\coloneqq \\veca_L + \\varu^{-1} \\cdot \\veca_R} \\aliceworks{\\vecb' \\coloneqq \\vecb_L + \\varu \\cdot \\vecb_R} \\alicebob{}{\\veca', \\vecb'}{} \\bobworks{\\vecG' \\coloneqq \\vecG_L + \\varu \\cdot \\vecG_R} \\bobworks{\\vecH' \\coloneqq \\vecH_L + \\varu^{-1} \\cdot \\vecH_R} \\bobworks{\\varC' \\coloneqq \\varu^{-1} \\cdot \\varL + \\varC + \\varu \\cdot \\varR} \\bobworks{\\varC' \\equalQ \\ip{\\veca'}{\\vecG'} + \\ip{\\vecb'}{\\vecH'} + \\ip{\\veca'}{\\vecb'} \\cdot \\varU} \\end{array} $$ $\\varu$ must be chosen randomly. If the prover can pick $\\varu$ then they can forge proofs. For instance, they can pick $\\varu = 1$ which gives them unconstrained control over $\\varC\u0026rsquo;$, through $\\varL$ and $\\varR$. $\\varC$, $\\vecG\u0026rsquo;$, $\\vecH\u0026rsquo;$, and $\\varC\u0026rsquo;$ must be honestly computed by the verifier. If the verifier accepts these values directly from the prover, then the prover can cheat by picking these values such that they are satisfied by some arbitrary vectors, unrelated to the original commitment; i.e., it would make the statement trivially satisfiable. This construction has perfect completeness and, as outline above, computational soundness. See Appendix B of [BBBPWM18] for a formal proof.\nThis construction requires the prover and verifier to exchange four group elements ($\\varC_P$, $\\varU$, $\\varL$ and $\\varR$), a scalar ($\\varu$), and two $n/2$-size vectors ($\\veca\u0026rsquo;$ and $\\vecb\u0026rsquo;$), giving total communication of size $n + 5$. This is about half the communication cost of Version 1.\nVersion 3: Non-Interactive Using the Fiat-Shamir Transform # Since Version 2 has the three-step commit-challenge-response structure we can apply the Fiat-Shamir transformation to make it non-interactive. We can compute the $\\varverifier$\u0026rsquo;s random challenges $\\varU \\coloneqq \\hashtogroup{\\vecG, \\vecH, \\varz, \\varC_P}$ and $\\varu \\coloneqq \\hashtofield{\\vecG, \\vecH, \\varz, \\varC_P, \\varU, \\varC, \\varL, \\varR}$ as hashes of all the public values encountered till that point.\nChoice of $\\HashToField$ and $\\HashToGroup$. For elliptic curves, see hash_to_field and hash_to_curve in draft-irtf-cfrg-hash-to-curve-16. Also, see Hash function choice for notes on handling tuple inputs. $$ \\begin{array}{lcl} \\uwork{\\varprover}{\\varverifier} \\aliceworks{\\varC_P \\coloneqq \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH}} \\aliceworks{\\varU \\coloneqq \\hashtogroup{\\vecG, \\vecH, \\varz, \\varC_P}} \\aliceworks{\\varC \\coloneqq \\varC_P + \\ip{\\veca}{\\vecb} \\cdot \\varU} \\aliceworks{\\varL \\coloneqq \\ip{\\veca_R}{\\vecG_L} + \\ip{\\vecb_L}{\\vecH_R} + \\ip{\\veca_R}{\\vecb_L} \\cdot \\varU} \\aliceworks{\\varR \\coloneqq \\ip{\\veca_L}{\\vecG_R} + \\ip{\\vecb_R}{\\vecH_L} + \\ip{\\veca_L}{\\vecb_R} \\cdot \\varU} \\aliceworks{\\varu \\coloneqq \\hashtofield{\\vecG, \\vecH, \\varz, \\varC_P, \\varU, \\varC, \\varL, \\varR}} \\aliceworks{\\vecG' \\coloneqq \\vecG_L + \\varu \\cdot \\vecG_R} \\aliceworks{\\vecH' \\coloneqq \\vecH_L + \\varu^{-1} \\cdot \\vecH_R} \\aliceworks{\\veca' \\coloneqq \\veca_L + \\varu^{-1} \\cdot \\veca_R} \\aliceworks{\\vecb' \\coloneqq \\vecb_L + \\varu \\cdot \\vecb_R} \\alicebob{}{\\varC_P, \\varL, \\varR}{} \\alicebob{}{\\veca', \\vecb'}{} \\bobworks{\\varU \\coloneqq \\hashtogroup{\\vecG, \\vecH, \\varz, \\varC_P}} \\bobworks{\\varC \\coloneqq \\varC_P + \\varz \\cdot \\varU} \\bobworks{\\varC' \\coloneqq \\varu^{-1} \\cdot \\varL + \\varC + \\varu \\cdot \\varR} \\bobworks{\\varu \\coloneqq \\hashtofield{\\vecG, \\vecH, \\varz, \\varC_P, \\varU, \\varC, \\varL, \\varR}} \\bobworks{\\vecG' \\coloneqq \\vecG_L + \\varu \\cdot \\vecG_R} \\bobworks{\\vecH' \\coloneqq \\vecH_L + \\varu^{-1} \\cdot \\vecH_R} \\bobworks{\\varC' \\equalQ \\ip{\\veca'}{\\vecG'} + \\ip{\\vecb'}{\\vecH'} + \\ip{\\veca'}{\\vecb'} \\cdot \\varU} \\end{array} $$ This construction has perfect completeness and, as outline above, computational soundness. See Appendix B of [BBBPWM18] for a formal proof.\nThis construction requires the prover to send three group elements ($\\varC_P$, $\\varL$, and $\\varR$) and two $n/2$-size vectors ($\\veca\u0026rsquo;$ and $\\vecb\u0026rsquo;$), giving total communication of size $n + 3$. This is almost the same as Version 2, but now with only one round of communication instead of three.\nVersion 4: Maximum Halving # Versions 2 and 3 halve the size of the vectors to generate a shorter proof. We can repeat this process successively with the halved vectors $\\log_2(n)$ times to reduce the size of the vectors to $1$ element.\nLet $\\varm \\coloneqq \\log_2(n)$ be the number of times we halve the vectors, and let us use a new variable $\\ctx$ to keep track of all the public values for use in the Fiat-Shamir hash.\nAlso, since the verifier does not need the intermediate halved generators $\\vecG_{\\varj}$ and $\\vecH_{\\varj}$ for $\\varj \u0026lt; \\varm$, it can directly compute the final halved generators $\\vecG_{\\varm}$ and $\\vecH_{\\varm}$: $$ \\begin{align} \\vecG_{\\varm} \u0026amp;= \\varG_1 + \\varu_{\\varm} \\varG_2 + \\varu_{\\varm-1} \\varG_3 + \\varu_{\\varm-1}\\varu_{\\varm} \\varG_4 + \\cdots + \\varu_1 \\varu_2 \\cdots \\varu_{\\varm} \\cdot \\varG_n\\\\ \\vecH_{\\varm} \u0026amp;= \\varH_1 + \\varu_{\\varm}^{-1} \\varH_2 + \\varu_{\\varm-1}^{-1} \\varH_3 + \\varu_{\\varm-1}^{-1}\\varu_{\\varm}^{-1} \\varH_4 + \\cdots + \\varu_1^{-1} \\varu_2^{-1} \\cdots \\varu_{\\varm}^{-1} \\cdot \\varH_n \\end{align} $$ and this can be done using multiscalar multiplication which is faster than multiplying by scalars one-by-one.\nGoing a step further, we can make use of the manner in which we compute the $\\vecG_{\\varm}$ ($\\varm$ rounds of multiply the right half by $\\varu_i$ and add to the left half), and similarly $\\vecH_{\\varm}$ to define the polynomials $$ \\begin{align} \\varg(X) \\coloneqq \\prod_{i=0}^{m-1} (1 + \\varu_{m-i} X^{2^i}) \u0026amp;= 1 + \\varu_{\\varm} X + \\varu_{\\varm-1} X^{2} + \\varu_{\\varm-1}\\varu_{\\varm} X^{3} + \\cdots + \\varu_1 \\cdots \\varu_{\\varm} X^{\\varn} \\\\ \\varh(X) \\coloneqq \\prod_{i=0}^{m-1} (1 + \\varu_{m-i}^{-1} X^{2^i}) \u0026amp;= 1 + \\varu_{\\varm}^{-1} X + \\varu_{\\varm-1}^{-1} X^{2} + \\varu_{\\varm-1}^{-1}\\varu_{\\varm}^{-1} X^{3} + \\cdots + \\varu_1^{-1} \\cdots \\varu_{\\varm}^{-1} X^{\\varn} \\end{align} $$ and write $\\vecG_{\\varm} = \\ip{\\vecg}{\\vecG}$ and $\\vecH_{\\varm} = \\ip{\\vech}{\\vecH}$ where $\\vecg$ and $\\vech$ are vectors corresponding to the polynomials $\\varg$ and $\\varh$ respectively.\nAmortization. The verifier can leverage the observation that $\\varG_{\\varm}$ and $\\varH_{\\varm}$ can be written as polynomial commitments to amortize the verification cost over multiple invocations. Rather than the verifier computing these values themselves for each invocation, at the end of all invocations, they can ask the prover to provide all these values along with a Schnorr-like proof that they were computed correctly. See Section 3.2 of [BGH19] for details. Note that the polynomial we use is different from the one in [BGH19] since we compute the half-size vectors differently. The full protocol looks as follows:\n$$ \\begin{array}{lcl} \\uwork{\\varprover}{\\varverifier} \\aliceworks{\\varC_P \\coloneqq \\ip{\\veca}{\\vecG} + \\ip{\\vecb}{\\vecH}} \\aliceworks{\\varU \\coloneqq \\hashtogroup{\\vecG, \\vecH, \\varz, \\varC_P}} \\aliceworks{\\varC_0 \\coloneqq \\varC_P + \\ip{\\veca}{\\vecb} \\cdot \\varU} \\aliceworks{\\ctx \\gets (\\vecG, \\vecH, \\varz, \\varC_P, \\varU, \\varC_0)} \\aliceworks{\\veca_0 \\coloneqq \\veca;\\; \\vecb_0 \\coloneqq \\vecb;\\; \\vecG_0 \\coloneqq \\vecG;\\; \\vecH_0 \\coloneqq \\vecH} \\aliceworks{\\text{For $i \\coloneqq 1$ to $\\varm$:}} \\aliceworks{\\indent \\varL_i \\coloneqq \\ip{\\veca_{i-1,R}}{\\vecG_{i-1,L}} + \\ip{\\vecb_{i-1,L}}{\\vecH_{i-1,R}} + \\ip{\\veca_{i-1,R}}{\\vecb_{i-1,L}} \\cdot \\varU} \\aliceworks{\\indent \\varR_i \\coloneqq \\ip{\\veca_{i-1,L}}{\\vecG_{i-1,R}} + \\ip{\\vecb_{i-1,R}}{\\vecH_{i-1,L}} + \\ip{\\veca_{i-1,L}}{\\vecb_{i-1,R}} \\cdot \\varU} \\aliceworks{\\indent \\ctx.\\append(\\varL_i, \\varR_i)} \\aliceworks{\\indent \\varu_i \\coloneqq \\hashtofield{\\ctx}} \\aliceworks{\\indent \\vecG_i \\coloneqq \\vecG_{i-1, L} + \\varu_i \\cdot \\vecG_{i-1,R}} \\aliceworks{\\indent \\vecH_i \\coloneqq \\vecH_{i-1,L} + \\varu_i^{-1} \\cdot \\vecH_{i-1,R}} \\aliceworks{\\indent \\veca_i \\coloneqq \\veca_{i-1,L} + \\varu_i^{-1} \\cdot \\veca_{i-1,R}} \\aliceworks{\\indent \\vecb_i \\coloneqq \\vecb_{i-1,L} + \\varu_i \\cdot \\vecb_{i-1,R}} \\alicebob{}{\\varC_P, (\\varL_1,\\varR_1),\\dots,(\\varL_{\\varm}, \\varR_{\\varm})}{} \\alicebob{}{\\veca_{\\varm}, \\vecb_{\\varm}}{} \\bobworks{\\varz \\mod \\varq \\gQ 0} \\bobworks{\\varC_P \\neq 0 \\text{ (point at infinity for EC groups)}} \\bobworks{\\varC_P \\inQ \\cgroup \\text{ (on curve check for EC groups)}} \\bobworks{\\varL_i, \\varR_i \\neq 0 \\text{ (point at infinity for EC groups)}} \\bobworks{\\varL_i, \\varR_i \\inQ \\cgroup \\text{ (on curve check for EC groups)}} \\bobworks{\\vara_i \\mod \\varq \\neq 0} \\bobworks{\\varb_i \\mod \\varq \\neq 0} \\bobwork{\\text{ for }i=1,\\ldots,m} \\bobseparator \\bobworks{\\varU \\coloneqq \\hashtogroup{\\vecG, \\vecH, \\varz, \\varC_P}} \\bobworks{\\varC_0 \\coloneqq \\varC_P + \\varz \\cdot \\varU} \\bobworks{\\ctx \\gets (\\vecG, \\vecH, \\varz, \\varC_P, \\varU, \\varC_0)} \\bobworks{\\text{For $i \\coloneqq 1$ to $\\varm$:}} \\bobworks{\\indent \\ctx.\\append(\\varL_i, \\varR_i)} \\bobworks{\\indent \\varu_i \\coloneqq \\hashtofield{\\ctx}} \\bobworks{\\indent \\varC_{i} \\coloneqq \\varu_{i}^{-1} \\cdot \\varL_{i} + \\varC_{i-1} + \\varu_{i} \\cdot \\varR_{i}} \\bobworks{\\vecg \\coloneqq \\varg(X) \\coloneqq \\prod_{i=0}^{m-1} (1 + \\varu_{m-i} X^{2^i})} \\bobworks{\\vech \\coloneqq \\varh(X) \\coloneqq \\prod_{i=0}^{m-1} (1 + \\varu_{m-i}^{-1} X^{2^i})} \\bobworks{\\vecG_{\\varm} \\coloneqq \\ip{\\vecg}{\\vecG}} \\bobworks{\\vecH_{\\varm} \\coloneqq \\ip{\\vech}{\\vecH}} \\bobworks{\\varC_{\\varm} \\equalQ \\ip{\\veca_{\\varm}}{\\vecG_{\\varm}} + \\ip{\\vecb_{\\varm}}{\\vecH_{\\varm}} + \\ip{\\veca_{\\varm}}{\\vecb_{\\varm}} \\cdot \\varU} \\end{array} $$ This construction has perfect completeness and, as outlined for Version 2, computational soundness. See Appendix B of [BBBPWM18] for a formal proof.\nThis construction requires the prover to send $2m + 1$ group elements ($\\varC_P, (\\varL_1, \\varR_1),\\dots,(\\varL_{\\varm}, \\varR_{\\varm})$) and two $1$-size vectors ($\\veca\u0026rsquo;$ and $\\vecb\u0026rsquo;$), giving total communication of size $2m + 3 = 2\\log_2(n) + 3$.\nSecurity Assumptions # Discrete logarithm: The security of this protocol relies on the hardness of discrete logarithm in the group $\\cgroup$. Specifically, it assumes that there are no known discrete log relations between the random generators. Concretely, for 128-bit security consider elliptic curve groups of size greater than $2^{256}$. Security Pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Weak Fiat-Shamir transform: When transforming the interactive protocol into a non-interactive protocol with the Fiat-Shamir transform, care needs to be taken to ensure that all parameters are included in the hash. See Fiat-Shamir transformation. Replay attacks: This construction does not provide replay protection; i.e., proofs can be replayed. But, replay protection can be achieved by adding more information to the $\\Hash$ invocations, see Preventing replay attacks. Malicious verifiers in interactive protocol: The interactive version of the halving protocol (Version 2) assumes an honest verifier. If the verifier deviates from the protocol, then security may no longer hold. See the warning in Section 2, and Using HVZKP in the wrong context. Verifier trusting the prover: All version of this protocol assume that the verifier does not trust the prover beyond the protocol. See the warning in Section 2. See also # IPA Polynomial Commitment "},{"id":19,"href":"/docs/zkdocs/commitments/","title":"Commitment Schemes","section":"Introduction","content":" Commitment Schemes Generally # Commitment schemes were introduced by Blum in 1981. Blum posed the following problem:\nAlice and Bob want to flip a coin by telephone. (They have just divorced, live in different cities, want to decide who gets the car.) Bob would not like to tell Alice HEADS and hear Alice (at the other end of the line) say \u0026ldquo;Here goes\u0026hellip; I\u0026rsquo;m flipping the coin\u0026hellip;. You lost!\u0026rdquo;\nBlum\u0026rsquo;s solution was a commitment scheme: a way for Bob to send his call of HEADS or TAILS ahead of time, but in a way that makes it impossible to change his mind later, and not to reveal his choice until Alice has flipped the coin. Once Alice has flipped the coin, Bob can reveal his call to Alice to see who won the coin toss.\nA commitment scheme has two phases:\nA commit phase, in which the committer generates the commitment value and shares it with others, and\nAn open phase, when the committer reveals the committed value, and the commitment is verified by others\nIt\u0026rsquo;s very important that Bob can\u0026rsquo;t cheat Alice by revealing a fake call. It\u0026rsquo;s also very important that Alice can\u0026rsquo;t gain any information about Bob\u0026rsquo;s call from his commitment. These are the two major features of a good commitment scheme:\nHiding: a commitment doesn\u0026rsquo;t reveal anything about the committed value\nBinding: it is not feasible to find two or more distinct values with the same commitment\nInformally, you can think of hiding as what keeps Alice from cheating (since she can\u0026rsquo;t get any information about Bob\u0026rsquo;s call to use against him), and binding as what keeps Bob from cheating (since he can\u0026rsquo;t \u0026ldquo;change his mind\u0026rdquo; and send a valid opening for $call\u0026rsquo;\\neq call$ if Alice announces a coin toss result he doesn\u0026rsquo;t like).\nLots of cryptographic protocols rely on this sort of exchange. For instance, this type of behavior is used in threshold signature schemes to allow a group of parties to securely generate an unbiased, uniformly random signing key.\nTo see an example of how this might be done using cryptography, consider the following process. Bob randomly selects $\\sampleGeneric{call}{{\\coinheads,\\cointails}}$ as his call. Then he selects a 256-bit random value $r$ and computes, $c=\\hmac{r}{call}$, then sends $c$ to Alice. Alice flips her coin, and announces either $\\coinheads$ or $\\cointails$. Bob then sends Alice $\\left(r,call\\right)$. Alice verifies that $c=\\hmac{r}{call}$. If the two match, she accepts Bob\u0026rsquo;s call as valid; otherwise, she rejects Bob\u0026rsquo;s call as invalid.\nWe call $c$ Bobs\u0026rsquo;s commitment to his call, and we call $\\left(r,call\\right)$ the opening of $c$.\nIn protocol terms, we have:\n$$ \\begin{array}{c} \\work{\\varalice}{\\varbob} \\bobwork{\\sampleGeneric{call}{\\{\\coinheads, \\cointails\\}}} \\bobwork{\\sampleGeneric{r}{\\{0, 1\\}^{256}}} \\bobwork{c_{A}=\\hmac{r}{call}} \\bobalice{}{c_{A}}{} \\alicework{\\sampleGeneric{toss}{\\{\\coinheads, \\cointails\\}}} \\alicebob{}{toss}{} \\bobalice{}{\\left(call,r\\right)}{} \\alicework{\\hmac{r}{call}\\equalQ c_{A} } \\end{array} $$ It\u0026rsquo;s worth noting that simply setting $C=\\hash{call}$ is problematic as a commitment mechanism. In our example, it would be trivial for Alice to compute $c_{\\coinheads}=\\hash{\\coinheads}$ and $c_{\\cointails}=\\hash{\\cointails}$ and compare them to Bob\u0026rsquo;s value for $C$.\nSimilarly, in our $\\mathsf{HMAC}$ scheme, if Bob doesn\u0026rsquo;t select a fresh $r$ for each commitment, Alice can detect when Bob commits to the same value in different contexts.\nOf course, the $\\mathsf{HMAC}$ scheme isn\u0026rsquo;t limited to simple $\\coinheads/\\cointails$ calls; it can be used for an arbitrary message $m$: $c=\\hmac{r}{m}$.\nThis scheme will be both hiding and binding due to the properties of the $\\mathsf{HMAC}$ function. Without $r$, Alice has no way of checking if $c$ commits to $\\coinheads$ or $\\cointails$, and it\u0026rsquo;s computationally infeasible for Bob to find $r\u0026rsquo;$ such that $c=\\hmac{r\u0026rsquo;}{call\u0026rsquo;}$ (where $call\u0026rsquo;\\neq call$).\nIt\u0026rsquo;s possible to create a commitment scheme that is hiding but not binding. Suppose the commitment $c_{A}$ above only included the lowest 16 bits of the HMAC output. It would take a fraction of a second for Bob to find $r\u0026rsquo;\\neq r$ such that $c=\\hmac{r\u0026rsquo;}{call\u0026rsquo;}$.\nConversely, it\u0026rsquo;s possible to have a commitment scheme that is binding but not hiding. The easiest example would be for Bob to simply send $call$ to Alice, as in the original, insecure coin flip protocol. Bob can\u0026rsquo;t change his mind after sending $c$, but nothing is hidden from Alice.\nSome specialized commitment schemes provide features beyond simple binding and hiding. The KZG polynomial commitment scheme, for instance, enables Bob to commit to a polynomial $f$ while allowing him to prove that a pair $\\left(x, y=f\\left(x\\right)\\right)$ represents a correct evaluation of $f$.\nPedersen Commitments An overview of the Pedersen commitment scheme and its applications KZG Polynomial Commitments Kate et. al\u0026rsquo;s Pairing-Based Polynomial Commitments IPA Polynomial Commitment An overview of the Inner Product Argument polynomial commitment scheme "},{"id":20,"href":"/docs/zkdocs/commitments/pedersen/","title":"Pedersen Commitments","section":"Commitment Schemes","content":" Pedersen Commitments # Pedersen commitments were originally described as part of Pedersen\u0026rsquo;s verifiable secret-sharing scheme in 1992. Section 3 of the Pedersen paper notes that the commitment scheme is \u0026ldquo;very similar\u0026rdquo; to a scheme proposed by Bos, Chaum, and Purdy in an unpublished set of notes proposing a voting system.\nPedersen commitments are simple. Committing to a value requires only two modular exponentiations and a multiplication. Because a random value is required for each commitment, commitments are non-deterministic. And, because Pedersen commitments rely heavily on group structure, they inherit a large number of useful properties that allow for useful operations and proofs for the committed values.\nPedersen\u0026rsquo;s original proposal described the commitment in terms of order-$q$ subgroups of $\\zns{p}$, but we will describe it in more generic terms, as it is applicable to any group $G$ where the discrete logarithm problem is believed to be hard (such as elliptic curve groups).\nDefinition # Start with a finite group $G$ of prime order $q$, where $q$ is suitably large. For instance, we can use an order-$q$ subgroup the multiplicative group $\\zps$ where $q$ divides $p$, or an elliptic curve group or subgroup. Select two generators $g,h$ of $G$ such that $\\log_{g}\\left(h\\right)$ is not known. The parameters of the commitment scheme are $\\left(G,q,g,h\\right)$.\nTo generate a commitment $c\\in G$ to a secret integer $s$, where $0 \u0026lt; s \u0026lt; q$, randomly sample $\\sampleN{t}{\\varq}$ and compute:\n$$ c = C_{g,h}\\left(s,t\\right)=g^{s}h^{t} $$\n(When $g,h$ are clear from context, we can simply write $C\\left(s,t\\right)$.)\nTo open the commitment, simply reveal $s$ and $t$.\nIntuition as to Why Pedersen Commitments are Binding # Suppose Alice has sent Bob a commitment $c=C\\left(s,t\\right)$ to a value $s$. She now wants to cheat by sending Bob an opening for $c$ that corresponds to $s\u0026rsquo;\\neq s$. In other words, she wants to break the binding property of Pedersen commitments.\nThat means Alice has to find $t\u0026rsquo;$ such that $g^{s\u0026rsquo;}h^{t\u0026rsquo;}=c$. Since $g^{s\u0026rsquo;}$ and $c$ are already fixed, Alice is left to solve $h^{t\u0026rsquo;}=cg^{-s\u0026rsquo;}$. In other words, she needs to compute $t\u0026rsquo;=\\log_{h}\\left(cg^{-s\u0026rsquo;}\\right)$. Since the discrete logarithm problem is supposed to be hard in $G$, Alice will have a difficult time finding $t\u0026rsquo;$.\nBefore committing to a value, Alice can also look for distinct pairs $\\left(s,t\\right),\\left(s\u0026rsquo;,t\u0026rsquo;\\right)$ such that $C\\left(s,t\\right)=C\\left(s\u0026rsquo;,t\u0026rsquo;\\right)$, without regard for the specific values of $s$ and $s\u0026rsquo;$. This is also equivalent to computing a discrete logarithm in $G$. As the Pedersen paper points out: given $C\\left(s,t\\right)=C\\left(s\u0026rsquo;,s\u0026rsquo;\\right)$, where $s\u0026rsquo;\\neq s$, then $t\u0026rsquo;\\neq t$, and it is possible to compute the discrete logarithm of $h$ with respect to $g$:\n$$ \\log_{g}\\left(h\\right)=\\frac{s-s\u0026rsquo;}{t\u0026rsquo;-t}\\pmod{q} $$\nTo summarize, breaking the binding property of Pedersen commitments is equivalent to solving the discrete log problem.\nIntuition as to Why Pedersen Commitments are Hiding # Suppose Alice has sent Bob a commitment $c=C\\left(s,t\\right)$ to a value $s$. Bob wants to cheat by figuring out $s$, or at least something about $s$, from $c$.\nRemember that $t$ is sampled uniformly at random, and so every value of $t$ is equally likely to be chosen, which means every value of $h^{t}$ is equally likely. Since $h$ is a generator of $G$, that means that $t$ \u0026ldquo;selects\u0026rdquo; every element of $G$ uniformly at random.\nIf Bob is able to gain any advantage in guessing the value of $s$ or $g^{s}$ from $c$, then he necessarily gains an advantage in guessing $t$ or $h^{t}$. However, $t$ is selected uniformly at random, so $h^{t}$ is a uniform random element of $G$. You can\u0026rsquo;t gain information about a uniform random distribution.\nThe Additive Property # Given two commitments, $c_{1}=C\\left(s_{1},t_{2}\\right)=g^{s_{1}}h^{t_{1}}$ and $c_{2}=C\\left(s_{2}, t_{2}\\right)=g^{s_{2}}h^{t_{2}}$, the product of $c_{1}$ and $c_{2}$ is $g^{s_{1}+s_{2}}h^{t_{1}+t_{2}} = C\\left(s_{1}+s_{2},t_{1}+t_{2}\\right)$. That is, the product of any two Pedersen commitments is a commitment to the sum of the committed values.\nThis also allows for scalar multiplication through exponentiation; $C\\left(x,y\\right)^{n}=C\\left(nx,ny\\right)$.\nThis additive property can be incredibly useful. It allows for a variety of operations to be performed on committed values before revealing them. Systems like Bulletproofs, for instance, exploit this property of the Pedersen scheme to commit to entire vectors of values at once, aggregating the commitments into a single value.\nUseful Algorithms and Properties of Pedersen Commitments # Proof of Knowledge of Secret # Given a commitment $A=C_{g,h}\\left(x,y\\right)=g^{x}h^{y}$, Alice can demonstrate to Bob that she knows $x$ and $y$ without revealing either $x$ or $y$. This is a useful protocol for protecting against the additive properties of Pedersen commitments being used maliciously. The protocol works as follows:\n$$ \\begin{array}{c} \\work{\\varalice}{\\varbob} \\alicework{\\sampleN{t_{1},t_{2}}{\\varq}} \\alicework{T = g^{t_{1}}h^{t_{2}}} \\alicebob{}{T}{} \\bobwork{\\sampleN{k}{\\varq}} \\bobalice{}{k}{} \\alicework{s_{1}=x \\cdot k+t_{1},s_{2}=y \\cdot k+t_{2}} \\alicebob{}{s_{1},s_{2}}{} \\bobwork{g^{s_{1}}h^{s_{2}} \\equalQ A^{k}T } \\end{array} $$ This works because:\n$$ g^{s_{1}}h^{s_{2}}=g^{xk+t_{1}}h^{yk+t_{2}}=g^{xk}h^{yk}g^{t_{1}}h^{t_{2}}=\\left(g^{x}h^{y}\\right)^{k}T=A^{k}T $$\nThis is secure because, in order to trick Bob, Alice needs to break the discrete log problem.\nA straightforward application of the Fiat-Shamir transform can turn this into a non-interactive proof. If Alice selects $k=\\hash{g\\Vert h\\Vert A\\Vert T}$, where the output of $\\hash{}$ has the same bit length as $q$, she can proceed as though $k$ were selected uniformly at random. Bob can compute $k$ in the same way, and verify the rest of the proof from there.\nAn Easy Proof of Equal Commitments # Given two commitments to a secret $s$ using the same set of generators, call them $c_{1}=C\\left(s,t_{1}\\right)$ and $c_{2}=C\\left(s,t_{2}\\right)$, where $t_{2}\\neq t_{1}$, Alice can easily show that both $c_{1}$ and $c_{2}$ commit to the same value. The simplest way, given by Pedersen, is for Alice to reveal $r=t_{1}-t_{2}\\pmod{q}$ to Bob.\nThis works because Bob can check that\n$$ c_{1}c_{2}^{-1}=g^{s}h^{t_{1}}g^{-s}h^{-t_{2}}=g^{s-s}h^{t_{1}-t_{2}}=h^{t_{1}-t_{2}}=h^{r} $$\nProof of Equal Commitments with Different Binding Generators # Suppose Alice has $c_{1}=C_{g_{1},h}\\left(s,t_{1}\\right)$ and $c_{2}=C_{g_{2},h}\\left(s,t_{2}\\right)$, possibly with $g_{1}\\neq g_{2}$. Alice can prove to Bob that $c_{1}$ and $c_{2}$ commit to the same value.\nAlice starts by selecting random integers $\\sampleN{r_{1},r_{2},r_{3}}{\\varq}$, then computing $c_{3}=C_{g_{1},h}\\left(r_{1},r_{2}\\right)=g_{1}^{r_{1}}h^{r_{2}}$ and $c_{4}=C_{g_{2},h}\\left(r_{1},r_{3}\\right)=g_{2}^{r_{1}}h^{r_{3}}$. She sends $c_{3},c_{4}$ to Bob.\nBob selects a random challenge value $\\sampleN{k}{\\varq}$ and sends it to Alice.\nAlice computes $z_{1}=ks+r_{1}$, $z_{2}=kt_{1}+r_{2}$, and $z_{3}=kt_{2}+r_{3}$ in $\\mathbb{Z}_{q}$ and sends $z_{1},z_{2},z_{3}$ to Bob.\nBob then checks that $c_{3}c_{1}^{k}=C_{g_{1},h}\\left(z_{1},z_{2}\\right)$ and $c_{4}c_{2}^{k}=C_{g_{2},h}\\left(z_{1},z_{3}\\right)$. If the condition holds, Bob accepts the proof as valid.\nThis works because:\n$$ c_{3}c_{1}^{k}=\\left(g_{1}^{r_{1}}h^{r_{2}}\\right)\\left(g_{1}^{s}h^{t_{1}}\\right)^{k}=g_{1}^{r_{1}}h^{r_{2}}g_{1}^{ks}h^{kt_{1}}=g_{1}^{ks+r_{1}}h^{kt_{1}+r_{2}}=g_{1}^{z_{1}}h^{z_{2}}=C_{g_{1},h}\\left(z_{1},z_{2}\\right) $$\nand\n$$ c_{4}c^{k}_{2}=\\left(g_{2}^{r_{1}}h^{r_{3}}\\right)\\left(g_{2}^{s}h^{t_{2}}\\right)^{k}=g_{2}^{r_{1}}h^{r_{3}}g_{2}^{ks}h^{kt_{2}}=g_{2}^{ks+r_{1}}h^{kt_{2}+r_{3}}=g_{2}^{z_{1}}h^{z_{3}}=C_{g_{2},h}\\left(z_{1},z_{3}\\right) $$\nIn diagram form: # $$ \\begin{array}{c} \\work{\\varalice}{\\varbob} \\alicework{\\sampleN{r_{1},r_{2},r_{3}}{\\varq}} \\alicework{c_{3}=C_{g_{1},h}\\left(r_{1},r_{2}\\right),c_{4}=C_{g_{2},h}\\left(r_{1},r_{3}\\right)} \\alicebob{}{c_{3},c_{4}}{} \\bobwork{\\sampleN{k}{\\varq}} \\bobalice{}{k}{} \\alicework{z_{1}=ks+r_{1}\\\\ z_{2}=kt_{1}+r_{2}\\\\ z_{3}=kt_{2}+r_{3}} \\alicebob{}{z_{1},z_{2},z_{3}}{} \\bobwork{c_{3}c_{1}^{k}\\equalQ C\\left(z_{1},z_{2}\\right)} \\bobwork{c_{4}c_{2}^{k}\\equalQ C\\left(z_{1},z_{3}\\right)} \\end{array} $$ Again, this can be made non-interactive through the use of a Fiat-Shamir transform. Alice can use $k=\\hash{g_{1}\\Vert g_{2}\\Vert h\\Vert c_{1}\\Vert c_{2}\\Vert c_{3}\\Vert c_{4}}$, again selecting a hash so that $k$ and $q$ have the same bit length.\nWhile this construction is more complicated, it has the benefit of allowing for commitments to be made when $g_{1}\\neq g_{2}$.\nProof of Squared Commitments # We can use the equality of commitments proof above to commit to both a secret $s$ and its square.\nSuppose Alice has a random $t_{1}$ and corresponding commitment $c_{1}=C_{g,h}\\left(s,t_{1}\\right)=g^{s}h^{t_{1}}$. Alice can select a random $t_{2}$ and compute $c_{2}=C_{c_{1},h}\\left(s,t_{2}\\right)=\\left(c_{1}\\right)^{s}h^{t_{2}}$\nNote that $c_{2}=C_{c_{1},h}\\left(s,t_{2}\\right)=\\left(c_{1}\\right)^{s}h^{t_{2}}=\\left(g^{s}h^{t_{1}}\\right)^{s}h^{t_{2}}=g^{s^{2}}h^{st_{1}+t_{2}}=C_{g,h}\\left(s^{2},st_{1}+t_{2}\\right)$, so $c_{2}$ is a commitment to $s^{2}$ in base $g$.\nOnce $c_{1}$ has been generated, Alice can easily generate $c_{2}$, provide both values to Bob, and use the equality proof above to demonstrate that $c_{2}$ commits to the square of the value committed to by $c_{1}$.\nSecurity Considerations # Generator Selection # Suppose that a Alice knows $l=\\log_{g}\\left(h\\right)$ and has a commitment $c=C\\left(s,t\\right)=g^{s}h^{t}$.\nThen Alice can rewrite the commitment as $c=g^{s}h^{t}$ as $c=g^{s}\\left(g^{l}\\right)^{t}=g^{s}g^{tl}=g^{s+tl}$. Let $s\u0026rsquo;=s+l$ and $t\u0026rsquo;=t-1$. She can the fraudulently \u0026ldquo;open\u0026rdquo; the commitment $c$ by sending $\\left(s\u0026rsquo;,t\u0026rsquo;\\right)$. This will appear as a valid opening to Bob, since:\n$$ g^{s\u0026rsquo;}h^{t\u0026rsquo;}=g^{s+1}\\left(g^{l}\\right)^{t - 1}=g^{s+l}g^{l\\left(t-1\\right)}=g^{s+l}g^{tl-l}=g^{s+tl}=g^{s+tl}=c $$\nIf the discrete logarithm of $h$ with respect to $g$ is known to Alice (or if an insecure group is chosen that makes computing the discrete log easy), the binding property is lost.\nThis is why it is important to ensure that generators $g$ and $h$ are selected independently. Ideally, $g$ and $h$ should be chosen independently from one another using a nothing-up-my-sleeve construction. For instance, $g$ and $h$ can be selected using an agreed-upon PRF and algorithm D.3.1 from the ANSI X9.62 standard (â€œFinding a Point on an Elliptic Curveâ€).\nRandom Number Generator Issues # In selecting the hiding value $\\sampleN{t}{\\varq}$, it is important that $t$ be truly uniform.\nSuppose there is an attack on the process used to generate $t$, and we have a set of commitments $c_{1}, c_{2},\\ldots,c_{n}$ to secrets $s_{1},s_{2},\\ldots,s_{n}$, not necessarily distinct. An attacker can then attack each $h^{t_{i}}$ and recover the corresponding values for $g^{s_{i}}$. From this, the attacker can quickly identify repeated commitments to the same value. In cases where commitments are suspected of having a simple linear relationship (e.g. $s_{i}=k\\cdot s_{j}$ or $s_{i}=s_{j} + k$ for some known value of $k$), these relationships can be recovered as well by examining $g^{s_{i}}g^{k}$ and $\\left(g^{s_{i}}\\right)^{k}$.\n"},{"id":21,"href":"/docs/zkdocs/protocol-primitives/shamir/","title":"Shamir's Secret Sharing Scheme","section":"Protocol primitives","content":" Shamirâ€™s Secret Sharing Scheme # Shamir\u0026rsquo;s Secret Sharing Scheme is a way of splitting a secret value $S$ into $n$ \u0026ldquo;pieces\u0026rdquo; (or \u0026ldquo;shares\u0026rdquo;) in such a way that any combination of $k$ pieces can be used to recover $S$, but any $k-1$ or fewer pieces provide no information about $S$.\nOverview of Secret Sharing # Shamir\u0026rsquo;s Secret Sharing Scheme relies on a very useful property of polynomials: any degree-$k$ polynomial can be uniquely identified by any set of $k+1$ distinct points. Two points define a line; three points define a parabola. However, with fewer than $k+1$ distinct points, no further information can be gained about the polynomial.\nThis leads directly to Shamir\u0026rsquo;s approach: encode a secret $S$ into a polynomial over a finite field, and distribute points on the polynomial as shares.\nSplitting $S$ # Given a secret $S$, a number of desired shares $n$, and a threshold $k$, splitting $S$ comes down to two steps:\nencode $S$ into a secret polynomial $f\\left(x\\right)$ of degree $k-1$ over a finite field $\\field{p}$ generate distinct shares $\\left(x_{i}, f(x_i)\\right)$ Encoding $S$ in a Polynomial # Shamir proposed a straightforward method for encoding secrets into polynomials: set the constant term of random polynomial to the secret $S$, and select all other coefficients uniformly at random. For a degree-$(k-1)$ polynomial, there would be $k-1$ random coefficients $r_i$, and the constant coefficient of $S$: $$f(x) = S + r_1 x + \\ldots + r_{k-1} x^{k-1} \\enspace.$$\nExample: We want to share our secret number 42 with three players so that any two of them can recover it. We define the degree-1 polynomial over $\\field{73}$ as $$f(x) = 42 + 13 \\cdot x \\enspace,$$ where 13 was randomly sampled over $\\field{73}$. We evaluate the polynomial at different points obtaining the shares $(x_i, f(x_i))$. Then, we can share 1 point of the coefficient to the three players, each getting one of $(1, 55), (2, 68), (3, 8)$. Since the polynomial is a line, any two of them could meet and recover the secret value 42! This choice has the advantage of relative simplicity; there is no need to use oddball sampling techniques to select the coefficients of $f\\left(x\\right)$.\nA Note on Selecting $p$ # In the general case, the specific prime $p$ does not matter much. Shamir\u0026rsquo;s original paper proposed using 16-bit primes (the largest of which would be $p=2^{16}-15=65521$) for performance reasons. By limiting intermediate results to 32 bits, multi-precision arithmetic routines could be avoided on any 32-bit processor. Large secrets could be broken into blocks of 16 bits or less and shared with distinct polynomials. One limitation imposed by such a small $p$ is that only about 65000 distinct shares can be generated.\nIn practice, $p$ should be reasonably large. Breaking $S$ into multiple parts introduces complexity and opportunities for malicious actors. Also, in some verifiable secret sharing schemes, a large $p$ is needed to prevent discrete log attacks.\nGenerating the Shares # Shares $s_{1},s_{2},\\ldots,s_{n}$ of $S$ are ordered pairs $\\left(x_{i}, f\\left(x_{i}\\right)\\right)$. The $x_{i}$ values can be picked in several ways, but a counter starting in 1 is the most common method.\nRecovering $S$ # The most common and direct method of recovering $S$ from the shares $s_{1},\\ldots,s_{k}$ is to evaluate $f\\left(0\\right)=S$ using Lagrange interpolation. It allows computing $f\\left(t\\right)$ for any $t\\in\\field{p}$ using the formula below:\n$$f\\left(t\\right) = \\displaystyle\\sum_{j=1}^{k}{y_{j}\\left(\\displaystyle\\prod_{\\begin{smallmatrix}1\\leq m\\leq k\\\\ m\\neq j\\end{smallmatrix}}{\\frac{t-x_m}{x_j - x_m}}\\right)}$$\nThe $t=0$ case slightly simplifies the product. Each product term can also be precomputed since it only depends on the $x$-coordinate of the shares that can be publicly known. $$f\\left(0\\right) = \\displaystyle\\sum_{j=1}^{k}{y_{j}\\left(\\displaystyle\\prod_{\\begin{smallmatrix}1\\leq m\\leq k\\\\ m\\neq j\\end{smallmatrix}}{\\frac{x_m}{x_m - x_j}}\\right)}$$\nThe Lagrange interpolating polynomial is popular because it\u0026rsquo;s fast enough for several use cases and relatively simple to implement.\nThe Zero Share Problem # How Shares are Generated # As mentioned above, there are several ways to select the $x_{i}$ values during the share-generation phase of the algorithm.\nThe most common approach, and the one we recommend, is to use a counter, setting $x_{i}=i$ for $i=1,2,\\ldots,n$. This has the advantage of simplicity and speed. No user-generated inputs are necessary, and evaluating $f\\left(x\\right)$ when $x$ is small can be faster than for arbitrary-selected values in the field.\nAnother approach is to use unique values associated with shareholders, such as userid values from a database, or users\u0026rsquo; provided values.\nFinally, some implementations select $x_{i}$ by selecting them randomly from $\\field{p}$.\nWhat Can Go Wrong? # Zero share problem: If it is possible to wind up with $x_{i}=0$ for some $i$, the corresponding share is $\\left(0, S\\right)$, revealing $S$ directly to the $i$-th shareholder. This is not a hypothetical attack; several instances of this problem have been spotted in the wild. Implementations must guarantee that all $x_i$ are modularly nonzero. Non-unique shares: The $x_i$ for each value must be modularly unique; when users reconstruct the secret from a share, they need to compute $\\frac{x_m}{x_m-x_j}$. If the polynomial is evaluated modulo $q$ and if $x_m\\equiv x_j \\pmod{q}$, the modular inverse of $(x_m-x_j)$ does not exist and the protocol does not work. Some applications do not check if this modular inverse exists and usually do not handle this gracefully. How Things Go Wrong # Counter-based shares: One of the most common control structures in programming is a loop with a starting index of i = 0. The line for(int i = 0; i \u0026lt; n; i++) is near-idiomatic in C; for i in range(n): is an idiom in Python. It\u0026rsquo;s easy to fall into an old pattern and fail to update these to the correct for(int i = 1; i \u0026lt;= n; i++) and for i in range(1, n + 1):, respectively. An initial draft of this page included this very error in the \u0026ldquo;correct\u0026rdquo; C loop! This common error is enough to destroy the security of the system entirely.\nUserid-based shares: Trusting unique user identifiers is problematic, too. A user can have a userid of 0 in plenty of systems. Trusting user-supplied values in security-critical contexts is never a good idea. Even if you compare the userid with 0, you might fail to do it correctly: since the polynomial evaluates over the finite field $\\field{p}$, you need to check if it is 0 in $\\field{p}$. In the case of the integers modulo a prime number, you must check that the userid is modularly different from zero. Even transforming user inputs can be problematic if you\u0026rsquo;re not careful. For instance, given a user input $n$, a program may try to avoid this issue by taking the $x$-coordinate of $n\\cdot G$, where $G$ is a generator of an elliptic curve group. However, if $n$ is 0, the resulting point is the \u0026ldquo;point at infinity\u0026rdquo;. With some curve parameterizations, the point at infinity is represented as $\\left(0,1\\right)$.\nRandom shares: Selecting random values seems safeâ€“ in theory, the probability of selecting 0 from $\\field{p}$ is $\\frac{1}{p}$. But winding up with a zero share is significantly more likely than that. Consider the case where a program generates random numbers by reading from /dev/random. For Linux kernels before version 5.6, it is possible for /dev/random to block when the \u0026ldquo;entropy runs out\u0026rdquo;. Since Linux 5.6, /dev/random can still block if the PRNG has not been initialized. If a programmer does not check the return value of the read function, then depending on how the destination buffer is allocated, the destination buffer can be left in a zeroed state, leading to a zero share.\n"},{"id":22,"href":"/docs/zkdocs/protocol-primitives/verifiable-secret-sharing/","title":"Feldman's Verifiable Secret Sharing","section":"Protocol primitives","content":" Feldman\u0026rsquo;s Verifiable Secret Sharing # As Feldman first introduced, Verifiable secret sharing is an extension to Shamir\u0026rsquo;s secret sharing scheme. The idea is that, when generating shares of the secret $S$, the splitting party also generates a set of public values that shareholders can use to validate their shares.\nFor simplicity, we will use \u0026ldquo;Sherry\u0026rdquo; to refer to the party generating the shares of a secret $S$. We denote a share using a lower-case $s$, and a shareholder (or player) as $P$. We will assume a $\\left(k, n\\right)$ threshold scheme, meaning that $k$ shares are enough to recover $S$ and fewer do not obtain any information about $S$. In some protocols, the players may perform the reconstruction, independently or collaboratively.\nShare Generation and Verification # Share Generation # In standard Shamir secret sharing, Sherry generates a polynomial $$ f \\left( x\\right) = a_{0} + a_{1} x + \\cdots + a_{k-1} x^{k-1} \\in \\mathbb{F}\\left[x\\right] \\enspace ,$$ where $a_{0}=S$ and $\\mathbb{F}$ is a finite field of characteristic $p$, where $p$ is a suitably large prime. Shares are generated as $s_{i}=\\left(x_{i},f\\left(x_{i}\\right)\\right)$ for $i=1,\\ldots,n$. Sherry then sends $s_{i}$ to $P_{i}$ over a secure channel. Shares are generated the same way in Feldman\u0026rsquo;s scheme.\nFeldman\u0026rsquo;s scheme extends Shamir\u0026rsquo;s scheme by having Sherry extend the shares to include verification values, as well as publicly share an additional set of values that each player $P_{i}$ can use to verify that their share $s_{i}$ is valid.\nThe public values are generated by translating them into elements a commutative group $G$ for which the discrete logarithm problem is hard. For expository purposes, we\u0026rsquo;ll start with $\\z{q}$, the multiplicative group of integers modulo a large prime $q$, where $q-1$ is divisible by a large prime $r$, and a generator value $g\\in\\z{q}$ such that $\\left|g\\right|=r$.\nVerification Values # Let $A_{j}=g^{a_{j}}\\pmod{q}$ for $j=0,\\ldots,k-1$. These are the verification values, and Sherry publishes all of them on a public broadcast channel.\nRecovering any $a_{j}$ values from the corresponding $A_{j}$ would require solving a discrete logarithm problem over $\\z{q}$, which is presumed to be hard. Note that $A_{0}=g^{a_{0}}=g^{S}\\pmod{q}$; solving the discrete log for $A_{0}$ would recover $S$ directly.\nVerification of Shares # To verify their share $s_{i}=\\left(x_{i},f\\left(x_{i}\\right)\\right)$, player $P_{i}$ computes:\n$$ V_{i}=\\prod_{j=0}^{k-1}{A_{j}^{x_{i}^{j}}} \\enspace . $$\nFor each $j$, we have $A_{j}=\\left(g^{a_{j}}\\right)^{x_{i}^{j}}=g^{a_{j}\\cdot x_{i}^{j}}$, which means\n$$ V_{i}=g^{a_{0}} g^{a_{1}\\cdot x_{i}} g^{a_{2}\\cdot x_{i}^{2}}\\cdots g^{a_{k-1}\\cdot x_{i}^{k-1}}=g^{a_{0} + a_{1}\\cdot x_{i} + \\cdots + a_{k-1}\\cdot x_{i}^{k-1}}=g^{f\\left(x_{i}\\right)} $$\nSince $P_{i}$ knows $f\\left(x_{i}\\right)$ as part of their share, they can compute $V_{i}\u0026rsquo;=g^{f\\left(x_{i}\\right)}$ directly from the value of $f\\left(x_{i}\\right)$ given in $s_{i}$. If $V_{i}\u0026rsquo;=V_{i}$, then $P_{i}$ accepts $s_{i}$ as valid; otherwise, they reject $s_{i}$.\nVariations # Feldman points out that it is not necessary to use $\\z{q}$ for generating the verification values. The paper discusses using elliptic curves over finite fields. Using the more familiar point multiplication notation for an elliptic curve group $G$ with a generator point $P\\in G$, we have $V_{i}=\\left[a_{0}\\right]P+\\left[a_{1}x_{i}\\right]P+\\cdots +\\left[a_{k-1}x_{i}^{k-1}\\right]P=Y_{i}$.\nSecurity pitfalls # Forgery attack: Craige describes a forgery attack against Feldman\u0026rsquo;s technique when broadcast channels are incorrectly implemented. If an attacker can change each player\u0026rsquo;s view of a single $A_{j}$ value, then it is possible to forge invalid shares for each player that will pass the verification step. Zero share attacks: All of the pitfalls of Shamir\u0026rsquo;s secret sharing scheme (e.g., generation of zero shares) still apply. Improper parameter choice: The $p$, $q$, and $g$ values should be selected with care. While Shamir\u0026rsquo;s original paper suggested using $p=2^{16}-15=65521$, this will limit the coefficients to 16 bits; recovering the $a_{j}$ values from their corresponding $A_{j}$ values becomes trivial. Further, improper selection of $q$ or $g$ can lead to several discrete log attacks. "},{"id":23,"href":"/docs/zkdocs/commitments/kzg_polynomial_commitment/","title":"KZG Polynomial Commitments","section":"Commitment Schemes","content":" KZG Polynomial Commitments # Overview of Polynomial Commitments # Polynomial commitment schemes allow one party to prove to another the correct evaluation of a polynomial at some set of points, without revealing any other information about the polynomial. A generalization of scalar commitment schemes such as Pedersen commitments, polynomial commitments are an important building block in zero-knowledge protocols; once the prover has committed to a polynomial, the verifier can query the value of the polynomial at one or many points and be assured that the responses are consistent with some predetermined polynomial which was selected without knowledge of the challenge queries.\nKate et. al.\u0026rsquo;s polynomial commitment scheme [KZG2010] consists, similarly to Pedersen commitments, of two phases.\nDuring the commit phase, $\\varprover$ generates a commitment to some polynomial $\\varf(\\varx)$ and shares it with $\\varverifier$. During the open phase, $\\varprover$ evaluates $\\varf$ at some point $\\varx_0$ and sends $\\langle \\varx_0, \\varf(\\varx_0), \\varw\\rangle$, where $\\varw$ is a proof (or \u0026ldquo;witness\u0026rdquo;) such that $\\varverifier$ can check the correct evaluation of $\\varf$ at $\\varx_0$. The commitment satisfies certain security properties:\nHiding: Given a commitment to an unknown degree-$t$ polynomial $\\varf$ and up to $t$ openings $\\langle \\varx_1, \\varf(\\varx_1), \\varw_1\\rangle, \\dots, \\langle \\varx_t, \\varf(\\varx_t), \\varw_t\\rangle$, one cannot find the value of $\\varf$ at any point not already queried. Binding: It is computationally infeasible to construct a commitment $\\varC$ and two distinct valid openings $\\langle\\varx_0, \\vary, \\varw\\rangle, \\langle\\varx_0, \\vary\u0026rsquo;, \\varw\u0026rsquo;\\rangle$ at the same point $\\varx_0$. Applications of Polynomial Commitments # Polynomial commitments serve as an important component of several modern noninteractive proof systems.\nVector Commitments # Given a vector $\\vec{v} = [v_1, v_2, \\dots, v_n]$ we can create a succinct commitment to the whole vector $\\vec{v}$ by interpolating a degree-$(n-1)$ polynomial $\\varf$ such that $\\varf(i) = v_i$. This enables provers to commit to a vector of field elements such that openings prove the value at a specific index. Vector commitments can in turn be used as a building block for Verkle Trees, a variant of Merkle trees with extremely small proof sizes.\nzkSNARKs # Polynomial commitment schemes are a core primitive in zkSNARKs such as [PLONK] and [Groth16] . These general-purpose zero knowledge proofs encode computations as polynomial identity constraints and then use openings of polynomial commitments at random points to verify polynomial equality. The power of polynomial commitments here comes from the fact that two distinct degree-$t$ polynomials over a field of order $q \u0026gt; t$ may intersect in at most $t$ points, and thus agree at a random point with probability at most $\\frac{t}{q}$.\nThe KZG Construction # Bilinear Pairings # KZG is a pairing-based protocol, meaning it works over a group with an efficiently computable bilinear pairing.\nLet $\\cgroup_1$, $\\cgroup_2$ and $\\cgroup_T$ be abelian groups of prime order $\\varq$. $\\cgroup_1$ and $\\cgroup_2$ will be written additively while $\\cgroup_T$ will be multiplicative. A bilinear pairing is an efficiently computable function $e: \\cgroup_1 \\times \\cgroup_2 \\rightarrow \\cgroup_T$ such that\n$$ e(a\\cdot x, b \\cdot y) = e(x, y)^{ab} $$ for all $x \\in \\cgroup_1, y \\in \\cgroup_2$. We generally assume that $e$ is non-degenerate, meaning that $e$ is not the trivial function mapping all pairs to $1_{\\cgroup_T}$.\nThe KZG commitment scheme was originally presented in the \u0026ldquo;type-1\u0026rdquo; setting, where $\\cgroup_1 = \\cgroup_2$. In practice, and in our presentation here, the scheme is generally implemented in the \u0026ldquo;type-3\u0026rdquo; setting, where $\\cgroup_1 \\neq \\cgroup_2$ in the sense that there is no efficiently computable isomorphism between the two groups.\nCommon choices of pairing-friendly groups are the Barreto-Naehrig [BN05] and Barreto-Lynn-Scott curves [BLS12-381] .\nTrusted Setup # KZG requires a setup procedure to be carried out by a trusted third party. In practice this setup is often performed as a distributed multiparty computation, such that as long as one participant is honest the setup is secure.\nThe public parameters are $\\cgroup_1$, $\\cgroup_2$ and $\\cgroup_T$, with generators $g_1 \\in \\cgroup_1, g_2 \\in \\cgroup_2$ and $e: \\cgroup_1 \\times \\cgroup_2 \\rightarrow \\cgroup_T$ a nondegenerate bilinear pairing. Let $t \\in \\mathbb{N}$ also be publicly chosen; $t$ will be the maximum degree of committed polynomials.\nThe setup procedure then computes\n$$ \\begin{align*} \\mathbf{SK} \u0026= \\sample{\\alpha}\\\\ \\mathbf{PK} \u0026= \\langle g_1, \\alpha\\cdot g_1, \\alpha^2 \\cdot g_1, \\dots, \\alpha^t \\cdot g_1, g_2, \\alpha \\cdot g_2\\rangle \\end{align*} $$ and publishes $\\mathbf{PK}$.\nThis pre-generated $\\mathbf{PK}$ is sometimes known as a \u0026ldquo;Structured Reference String\u0026rdquo; $\\mathbf{SK}$ must be kept secret and destroyed.\nIf a party knows the value $\\alpha$ then they can forge openings of a commitment to $\\varf$ at $\\varx_0$ with putative value $\\vary$ by computing\n$\\varw = (\\varf(\\alpha) / (\\alpha - \\varx_0) - \\vary) \\cdot g_1$\nCommit # A commitment to a polynomial $\\varf$ is simply the group element $\\varf(\\alpha) \\cdot g_1$. Because the prover does not know $\\alpha$ and thus cannot compute the value $\\varf(\\alpha)$ directly, the evaluation is carried out in the exponent as follows:\nGiven $\\mathbf{PK}$, to form a commitment to $\\varf \\in \\mathbb{Z}_q[X]$ with $\\varf(X) = \\sum_{i = 0}^{t} c_i X^i$, compute and publish $$\\varC = \\sum_{i=0}^t c_i \\cdot (\\alpha^i \\cdot g_1)$$ Open # For any degree-$t$ polynomial $\\varf$, the polynomial $(\\varf(X) - \\varf(x_0))$ has a root at $x_0$ and thus can be factored as $$\\varf(X) - \\varf(x_0) = (X - \\varx_0) \\varf_{\\varx_0}(X)$$ for some degree-$(t-1)$ polynomial $\\varf_{\\varx_0}$. The witness to an opening of $\\varf$ at $\\varx_0$ is then $\\varw = \\varf_{\\varx_0}(\\alpha) \\cdot g_1$.\nMore concretely, to open a commitment $\\varC$ to polynomial $\\varf$ at point $\\varx_0$, compute the quotient $$\\varf_{\\varx_0}(X) = \\frac{\\varf(X) - \\varf(\\varx_0)}{X - \\varx_0} = \\sum_{i = 0}^{t} c_i X^i$$ and compute the witness as $$\\varw = \\varf_{\\varx_0}(\\alpha)\\cdot g_1 = \\sum_{i=0}^t c_i \\cdot (\\alpha^i \\cdot g_1)$$\nReveal $\\langle \\varx_0, \\varf(\\varx_0), \\varw \\rangle$.\nVerify # Verification of an opening of $\\varf$ at $\\varx_0$ with witness $\\varw = \\varf_{\\varx_0}(\\alpha)\\cdot g_1$ amounts to checking in the exponent that $\\varf(\\alpha) \\equalQ (X- \\varx_0)(\\alpha) \\cdot \\varf_{\\varx_0}(\\alpha) + \\varf(\\varx_0)$. Since the prover does not know the value of $\\alpha$, we can think of the check as happening at a random point and thus with high probability succeeds only if the polynomial identity $\\varf(X) \\equalQ (X- \\varx_0) \\cdot \\varf_{\\varx_0}(X) + \\varf(\\varx_0)$ holds at all points.\nConcretely, to verify an evaluation $\\langle \\varx_0, \\varf(\\varx_0), \\varw \\rangle$ on commitment $\\varC$, check $$e(\\varC, g_2) \\equalQ e(\\varw, \\alpha \\cdot g_2 - \\varx_0 \\cdot g_2) \\cdot e(g_1, g_2)^{\\varf(\\varx_0)}$$\nTo see that the scheme is complete in the sense that every correctly computed opening passes verification, we compute\n$$ \\begin{align*} \u0026e(\\varw, \\alpha \\cdot g_2 - \\varx_0 \\cdot g_2) \\cdot e(g_1, g_2)^{\\varf(\\varx_0)}\\\\ \u0026= e(\\varf_{\\varx_0}(\\alpha)\\cdot g_1, (\\alpha - \\varx_0)\\cdot g_2) \\cdot e(g_1, g_2)^{\\varf(\\varx_0)}\\\\ \u0026= e(g_1, g_2)^{\\varf_{\\varx_0}(\\alpha)\\cdot (\\alpha - \\varx_0) + \\varf(\\varx_0)}\\\\ \u0026= e(g_1, g_2)^{\\frac{\\varf(\\alpha) - \\varf(\\varx_0)}{\\alpha - \\varx_0} \\cdot (\\alpha - \\varx_0) + \\varf(\\varx_0)}\\\\ \u0026= e(g_1, g_2)^{\\varf(\\alpha)}\\\\ \u0026= e(\\varf(\\alpha)\\cdot g_1, g_2)\\\\ \u0026= e(\\varC, g_2) \\end{align*} $$ Hardness Assumptions # Discrete Logarithm # The hiding property of KZG commitments relies on the hardness of the discrete logarithm in the group $\\cgroup_1$.\n$t$-Strong Diffie Hellman # The binding property requires the $t$-Strong Diffie Hellman ($t$-SDH) assumption: Given $g, \\alpha \\cdot g, \\dots, \\alpha^t \\cdot g$ it is hard to find a pair $\\langle c, \\frac{1}{\\alpha + c} \\cdot g \\rangle$. This is a slightly stronger form of the $t$-Polynomial Diffie Hellman assumption that, given $g, \\alpha \\cdot g, \\dots, \\alpha^t \\cdot g$, it is hard to find $\\alpha^{t+1}\\cdot g$.\n$t$-SDH implies the computational Diffie Hellman assumption, as well as the hardness of the discrete logarithm problem.\nKZG Variants # Indistinguishable and Unconditionally hiding (\u0026ldquo;Pedersen\u0026rdquo;) variants # The KZG commitment scheme as presented above can be viewed as a generalization of the Discrete Log commitment $\\varC(\\varx) = \\varx \\cdot g$. This scheme is binding and is hiding against a computationally-bounded adversary when $\\varx$ is chosen uniformly at random, but lacks indistinguishability: if $\\varx$ is drawn from a small set known to the adversary then the adversary can distinguish which of the elements was committed. For example, if Alice wants to commit to a single bit $b \\in \\{0, 1\\}$ then she will either publish $0 \\cdot g = 0$ or $1 \\cdot g = g$ and Bob can clearly learn which bit was committed. Pedersen commitments solve this problem by adding a random masking value $r$ and an extra random public generator $h$ such that $\\varC_r(\\varx) = \\varx \\cdot g + r \\cdot h$. This commitment is now indistinguishable and unconditionally hiding: for any value $y$ there exists some unique $s$ such that $C_r(x) = x \\cdot g + r\\cdot h = y \\cdot g + s \\cdot h = C_s(y)$, so even a computationally-unbounded adversary cannot learn $x$ from $C_r(x)$, if $r$ is unknown.\nIn a similar vein, let $\\varf(\\varx)$ be a degree-$t$ polynomial.\nAn adversary capable of solving the Discrete Log problem can find the discrete log of $\\varC(\\varf) = {\\varf(\\alpha)} \\cdot g_1$ and acquire $\\langle \\alpha, \\varf(\\alpha)\\rangle$. Thus the scheme is only computationally hiding. If $\\varf(\\varx_0)$ is chosen from a small set, say $\\{0,1\\}$, then given $t$ openings an adversary can \u0026ldquo;guess and check\u0026rdquo; the value of $\\varf(\\varx_0)$. Thus the scheme does not possess indistinguishablity. There are two common approaches to resolve these issues:\nChoose one extra point on $f$ at random: if you want to commit to $t$ \u0026ldquo;useful\u0026rdquo; points, instead commit to $t+1$ points, where the last point is chosen uniformly at random. Then, any subset of the $t$ useful points may be revealed without breaking indistinguishablity. Use the \u0026ldquo;Pedersen Variant\u0026rdquo;: let $h_1$ be an agreed-upon random generator of $\\cgroup_1$. To commit to a degree-$t$ polynomial $\\varf$, choose a random degree-$t$ polynomial $\\hat{\\varf}$ and publish ${\\varf(\\alpha)}\\cdot g_1 + {\\hat{\\varf}(\\alpha)} \\cdot h_1$. To open at a point $\\varx_0$, let $$ w = {\\frac{\\varf(\\alpha) - \\varf(\\varx_0)}{\\alpha - \\varx_0}}\\cdot g_1 + {\\frac{\\hat{\\varf}(\\alpha) - \\hat{\\varf}(\\varx_0)}{\\alpha - \\varx_0}}\\cdot h_1 $$ reveal $\\varf(\\varx_0), \\hat{\\varf}(\\varx_0), wI$ Security note: $h_1$ must be chosen independently from $g_1$, i.e., no one may know the discrete log of $h_1$ with respect to $g_1$. If Alice knows $s$ such that $h_1 = s \\cdot g_1$ then the commitment scheme fails to be binding:\nIf $h_1 = s \\cdot g_1$ then $$\\begin{align*} \\varC_r(x) \u0026amp;= x \\cdot g_1 + r \\cdot h_1\\\\ \u0026amp;= x\\cdot g_1 + {(s \\cdot r)}\\cdot g_1\\\\ \u0026amp;= (x + (y - x) + s(r - \\frac{y - x}{s}))\\cdot g_1\\\\ \u0026amp;= y\\cdot g_1 + (r - \\frac{y - x}{s})\\cdot h_1\\\\ \u0026amp;= C_{r-\\frac{(y - x)}{s}}(y) \\end{align*} $$\nSecurity Pitfalls # Small-order elements: Pairing based cryptography often involves elliptic curve groups of composite order. Any elliptic curve points accepted from untrusted parties must be verified to reside in the proper large prime-order subgroup. Polynomial interpolation: If $t+1$ points on a degree-$t$ polynomial are revealed, then all further points can be recovered. Trusted setup: If using a trusted setup, $\\mathbf{SK}$ must be generated with strong randomness and erased immediately after generating $\\mathbf{PK}$. "},{"id":24,"href":"/docs/zkdocs/commitments/ipa-pcs/","title":"IPA Polynomial Commitment","section":"Commitment Schemes","content":" IPA Polynomial Commitment # Overview of IPA Polynomial Commitment # The inner product argument was introduced by Bootle et al. [BCCGP16] , and refined in Bulletproofs [BBBPWM18] . This protocol was specialized to polynomial commitments in [BGH19] then further studied and refined in [BCMS20] .\nGoal: $\\varprover$ convinces $\\varverifier$ that they know a secret polynomial $\\varf$ such that $\\varf(\\varx) = \\varv$, for evaluation point $\\varx$ and evaluation $\\varv$; and this satisfies the polynomial commitment $\\varC_{\\varP}$. Public input: a cyclic additive group $\\cgroup$ of prime order $\\varq$ and $n+1$ random $\\cgroup$ generators $\\vecG = (\\varG_1,\\dots,\\varG_n)$ and $\\varH$; polynomial commitment $\\varC_{\\varP} \\in \\cgroup$, scalar $\\varx \\in \\zq$, and scalar $\\varv \\in \\zq$.\nPrivate input: $\\varprover$ knows secret polynomial $\\varf$ that satisfies the polynomial commitment $\\varC_P$ and $\\varf(\\varx) = \\varv$.\nComparison with KZG Polynomial Commitments. IPA PCS requires fewer assumptions but is less efficient. IPA does not require a trusted setup and only assumes discrete log, whereas KZG requires a trusted setup and assumes pairings. But, IPA proofs are $O(\\log \\varn)$ and the verifier needs to do $O(n)$ work, whereas KZG proofs are $O(1)$ and the verifier only needs to do $O(1)$ work. That said, the verification time for IPA proofs can be amortized over multiple runs.\nPolynomial Commitment from IPA # In this section, we build polynomial commitments from IPA over two successive versions.\nVersion 1: A Simple, Non-Hiding Construction # The most straightforward way to do polynomial commitments is to interpret the polynomial $f(\\varX) = \\vara_1 + \\vara_2 \\varX + \\vara_3 \\varX^2 + \\cdots + \\vara_{\\varn} \\varX^{\\varn-1}$ as a vector of coefficients $(a_1,\\dots,a_{\\varn})$ and fix the other vector to be powers of the evaluation point $\\vecb = (1, \\varx, \\varx^2, \\dots, \\varx^{\\varn-1})$. Then their inner product $$ \\ip{\\veca}{\\vecb} = \\vara_1 + \\vara_2 \\varx + \\vara_3 \\varx^2 + \\cdots + \\vara_{\\varn} \\varx^{\\varn-1} $$ is the evaluation $f(x)$.\nSince $\\vecb$ is now public, the prover no longer has to commit to it. So, the verifier can compute the reduced value $\\vecb_{\\varm}$ similar to how it computes $\\vecG_{\\varm}$ in the Inner Product Argument using the polynomial $\\varg(\\varX) \\coloneqq \\prod_{i=0}^{\\varm-1} (1 + \\varu_{\\varm-i} \\varX^{2^i})$: $$ \\begin{align} \\vecG_{\\varm} \u0026amp;= \\varG_1 + \\varu_{\\varm} \\varG_2 + \\cdots + \\varu_1 \\varu_2 \\cdots \\varu_{\\varm} \\cdot \\varG_n = \\ip{\\vecg}{\\vecG}\\\\ \\vecb_{\\varm} \u0026amp;= 1 + \\varu_{\\varm} \\varx + \\cdots + \\varu_1 \\varu_2 \\cdots \\varu_{\\varm} \\cdot \\varx^{\\varn-1} = \\ip{\\vecg}{\\vecb}\\\\ \\end{align} $$\nThe full protocol, adapted from Version 4 in Inner Product Argument is as follows:\n$$ \\begin{array}{lcl} \\uwork{\\varprover}{\\varverifier} \\aliceworks{\\veca \\coloneqq (\\vara_1,\\dots,\\vara_{\\varn})} \\dupwork{\\vecb \\coloneqq (1, \\varx, \\varx^2, \\dots, \\varx^{\\varn-1})} \\aliceworks{\\varC_P \\coloneqq \\ip{\\veca}{\\vecG}} \\aliceworks{\\varU \\coloneqq \\hashtogroup{\\vecG, \\varx, \\varv, \\varC_P}} \\aliceworks{\\varC_0 \\coloneqq \\varC_P + \\ip{\\veca}{\\vecb} \\cdot \\varU} \\aliceworks{\\ctx \\gets (\\vecG, \\varx, \\varv, \\varC_P, \\varU, \\varC_0)} \\aliceworks{\\veca_0 \\coloneqq \\veca;\\; \\vecb_0 \\coloneqq \\vecb;\\; \\vecG_0 \\coloneqq \\vecG} \\aliceworks{\\text{For $i \\coloneqq 1$ to $\\varm$:}} \\aliceworks{\\indent \\varL_i \\coloneqq \\ip{\\veca_{i-1,R}}{\\vecG_{i-1,L}} + \\ip{\\veca_{i-1,R}}{\\vecb_{i-1,L}} \\cdot \\varU} \\aliceworks{\\indent \\varR_i \\coloneqq \\ip{\\veca_{i-1,L}}{\\vecG_{i-1,R}} + \\ip{\\veca_{i-1,L}}{\\vecb_{i-1,R}} \\cdot \\varU} \\aliceworks{\\indent \\ctx.\\append(\\varL_i, \\varR_i)} \\aliceworks{\\indent \\varu_i \\coloneqq \\hashtofield{\\ctx}} \\aliceworks{\\indent \\vecG_i \\coloneqq \\vecG_{i-1, L} + \\varu_i \\cdot \\vecG_{i-1,R}} \\aliceworks{\\indent \\veca_i \\coloneqq \\veca_{i-1,L} + \\varu_i^{-1} \\cdot \\veca_{i-1,R}} \\aliceworks{\\indent \\vecb_i \\coloneqq \\vecb_{i-1,L} + \\varu_i \\cdot \\vecb_{i-1,R}} \\alicebob{}{\\varC_P, (\\varL_1,\\varR_1),\\dots,(\\varL_{\\varm}, \\varR_{\\varm})}{} \\alicebob{}{\\veca_{\\varm}}{} \\bobworks{\\varU \\coloneqq \\hashtogroup{\\vecG, \\varx, \\varv, \\varC_P}} \\bobworks{\\varC_0 \\coloneqq \\varC_P + \\varv \\cdot \\varU} \\bobworks{\\ctx \\gets (\\vecG, \\varx, \\varv, \\varC_P, \\varU, \\varC_0)} \\bobworks{\\text{For $i \\coloneqq 1$ to $\\varm$:}} \\bobworks{\\indent \\ctx.\\append(\\varL_i, \\varR_i)} \\bobworks{\\indent \\varu_i \\coloneqq \\hashtofield{\\ctx}} \\bobworks{\\indent \\varC_{i} \\coloneqq \\varu_{i}^{-1} \\cdot \\varL_{i} + \\varC_{i-1} + \\varu_{i} \\cdot \\varR_{i}} \\bobworks{\\vecg \\coloneqq \\varg(X) \\coloneqq \\prod_{i=0}^{m-1} (1 + \\varu_{m-i} X^{2^i})} \\bobworks{\\vecG_{\\varm} \\coloneqq \\ip{\\vecg}{\\vecG}} \\bobworks{\\vecb_{\\varm} \\coloneqq \\ip{\\vecg}{\\vecb}} \\bobworks{\\varC_{\\varm} \\equalQ \\ip{\\veca_{\\varm}}{\\vecG_{\\varm}} + \\ip{\\veca_{\\varm}}{\\vecb_{\\varm}} \\cdot \\varU} \\end{array} $$ This construction is not hiding. This construction reveals $\\veca_{\\varm}$ which in turns leaks at least one bit of information about $\\veca = \\varf$. Amortization. The computation of $\\vecG_{\\varm}$ and $\\vecb_{\\varm}$ (the only linear time computations the verifier needs to do) can be amortized over multiple runs, see \u0026ldquo;Amortization\u0026rdquo; in Inner Product Argument for details. Version 2: Hiding Construction # Version 1 did not hide the polynomial $\\varf$ and thus was not zero-knowledge. This version remedies that by using hiding commitments and an intermediate random-looking polynomial.\nFirst, we compute a hiding commitment $\\varC_P$ to the polynomial $\\varf$. Let $\\veca$ and $\\vecb$ be the coefficients of $\\varf$ and powers of the evaluation point $\\varx$, respectively, as before. The prover samples a random blinding factor $\\sample{\\vart}$ and computes $$ \\varC_P \\coloneqq \\ip{\\veca}{\\vecG} + \\vart \\cdot \\varH $$\nSecond, we compute a random-looking polynomial. Sample a random polynomial $p_r(\\varX) \\coloneqq \\vars_1 + \\vars_2 \\varX + \\vars_3 \\varX^2 + \\cdots + \\vars_{\\varn} \\varX^{\\varn-1}$ of the same degree as $\\varf$ by picking random coefficients $\\vars_1,\\dots,\\vars_{\\varn}$. Construct $\\bar{\\varf} \\coloneqq p_r - p_r(\\varx)$ so that $\\bar{\\varf}$ looks random and has a root at the evaluation point $\\varx$; that is, $\\bar{\\varf}(\\varx) = 0$.\nThird, we compute a hiding commitment to the random-looking polynomial. Let $\\bar{\\veca} \\coloneqq (\\varw_{1},\\dots,\\varw_{\\varn})$ be the coefficients of $\\bar{\\varf}$. The prover samples a random blinding factor $\\sample{\\bar{\\vart}}$ and computes the commitment $$ \\bar{\\varC}_P \\coloneqq \\ip{\\bar{\\veca}}{\\vecG} + \\bar{\\vart} \\cdot \\varH $$\nFourth, we blind the polynomial $\\varf$ using the random-looking polynomial $\\bar{\\varf}$. After receiving these commitments, the verifier samples some randomness $\\varalpha$ and the prover uses it to compute the blinded polynomial $\\varf\u0026rsquo; \\coloneqq \\varf + \\varalpha \\cdot \\bar{\\varf}$. Let $\\vecc = (\\varc_1,\\dots,\\varc_n)$ be the coefficients of $\\varf\u0026rsquo;$. The prover computes the corresponding randomness $\\vart\u0026rsquo; \\coloneqq \\vart + \\varalpha \\cdot \\bar{\\vart}$ and uses it to compute a non-hiding commitment to $\\varf\u0026rsquo;$ as $\\varC_P\u0026rsquo; \\coloneqq \\varC_P + \\varalpha \\cdot \\bar{\\varC}_P - \\vart\u0026rsquo; \\cdot \\varH = \\ip{\\vecc}{\\vecG}$.\nNow we continue with the halving like Version 1, except using the blinded polynomial $\\varf\u0026rsquo;$ in place of the original polynomial $\\varf$. The full protocol is below.\n$$ \\begin{array}{lcl} \\uwork{\\varprover}{\\varverifier} \\aliceworks{\\veca \\coloneqq (\\vara_1,\\dots,\\vara_{\\varn})} \\dupwork{\\vecb \\coloneqq (1, \\varx, \\varx^2, \\dots, \\varx^{\\varn-1})} \\aliceworks{\\sample{\\vart}} \\aliceworks{\\varC_P \\coloneqq \\ip{\\veca}{\\vecG} + \\vart \\cdot \\varH} \\aliceworks{\\sampleGeneric{\\varp_r}{\\zq^{\\varn}}} \\aliceworks{\\bar{\\varf} \\coloneqq \\varp_r - \\varp_r(\\varx)} \\aliceworks{\\bar{\\veca} \\coloneqq (\\varw_1,\\dots,\\varw_n) = \\bar{\\varf}} \\aliceworks{\\sample{\\bar{\\vart}}} \\aliceworks{\\bar{\\varC}_P \\coloneqq \\ip{\\bar{\\veca}}{\\vecG} + \\bar{\\vart} \\cdot \\varH} \\aliceworks{\\ctx \\gets (\\vecG, \\varH, \\varx, \\varv, \\varC_P, \\bar{\\varC}_P)} \\aliceworks{\\varalpha \\coloneqq \\hashtofield{\\ctx}} \\aliceworks{\\vecc \\coloneqq \\veca + \\alpha \\cdot \\bar{\\veca} = \\varf'} \\aliceworks{\\vart' \\coloneqq \\vart + \\varalpha \\cdot \\bar{\\vart}} \\aliceworks{\\varC_P' \\coloneqq \\varC_P + \\varalpha \\cdot \\bar{\\varC}_P - \\vart' \\cdot \\varH = \\ip{\\vecc}{\\vecG}} \\aliceworks{\\ctx.\\append(\\varC_P')} \\aliceworks{\\varU \\coloneqq \\hashtogroup{\\ctx}} \\aliceworks{\\varC_0 \\coloneqq \\varC_P + \\ip{\\veca}{\\vecb} \\cdot \\varU} \\aliceworks{\\ctx.\\append(\\varC_0)} \\aliceworks{\\vecc_0 \\coloneqq \\vecc;\\; \\vecb_0 \\coloneqq \\vecb;\\; \\vecG_0 \\coloneqq \\vecG} \\aliceworks{\\text{For $i \\coloneqq 1$ to $\\varm$:}} \\aliceworks{\\indent \\varL_i \\coloneqq \\ip{\\veca_{i-1,R}}{\\vecG_{i-1,L}} + \\ip{\\veca_{i-1,R}}{\\vecb_{i-1,L}} \\cdot \\varU} \\aliceworks{\\indent \\varR_i \\coloneqq \\ip{\\veca_{i-1,L}}{\\vecG_{i-1,R}} + \\ip{\\veca_{i-1,L}}{\\vecb_{i-1,R}} \\cdot \\varU} \\aliceworks{\\indent \\ctx.\\append(\\varL_i, \\varR_i)} \\aliceworks{\\indent \\varu_i \\coloneqq \\hashtofield{\\ctx}} \\aliceworks{\\indent \\vecG_i \\coloneqq \\vecG_{i-1, L} + \\varu_i \\cdot \\vecG_{i-1,R}} \\aliceworks{\\indent \\vecc_i \\coloneqq \\vecc_{i-1,L} + \\varu_i^{-1} \\cdot \\vecc_{i-1,R}} \\aliceworks{\\indent \\vecb_i \\coloneqq \\vecb_{i-1,L} + \\varu_i \\cdot \\vecb_{i-1,R}} \\alicebob{}{\\varC_P, (\\varL_1,\\varR_1),\\dots,(\\varL_{\\varm}, \\varR_{\\varm})}{} \\alicebob{}{\\bar{\\varC}_P, \\veca_{\\varm}, \\vart'}{} \\bobworks{\\varv \\mod \\varq \\gQ 0} \\bobworks{\\varx \\mod \\varq \\gQ 0} \\bobworks{\\vart' \\mod \\varq \\gQ 0} \\bobworks{\\varC_P \\neq 0 \\text{ (point at infinity for EC groups)}} \\bobworks{\\varC_P \\inQ \\cgroup \\text{ (on curve check for EC groups)}} \\bobworks{\\bar{\\varC}_P \\neq 0 \\text{ (point at infinity for EC groups)}} \\bobworks{\\bar{\\varC}_P \\inQ \\cgroup \\text{ (on curve check for EC groups)}} \\bobworks{\\varL_i, \\varR_i \\neq 0 \\text{ (point at infinity for EC groups)}} \\bobworks{\\varL_i, \\varR_i \\inQ \\cgroup \\text{ (on curve check for EC groups)}} \\bobworks{\\vara_i \\mod \\varq \\neq 0} \\bobwork{\\text{ for }i=1,\\ldots,m} \\bobseparator \\bobworks{\\ctx \\gets (\\vecG, \\varH, \\varx, \\varv, \\varC_P, \\bar{\\varC}_P)} \\bobworks{\\varalpha \\coloneqq \\hashtofield{\\ctx}} \\bobworks{\\varC_P' \\coloneqq \\varC_P + \\varalpha \\cdot \\bar{\\varC}_P - \\vart' \\cdot \\varH} \\bobworks{\\ctx.\\append(\\varC_P')} \\bobworks{\\varU \\coloneqq \\hashtogroup{\\ctx}} \\bobworks{\\varC_0 \\coloneqq \\varC' + \\varv \\cdot \\varU} \\bobworks{\\ctx.\\append(\\varC_0)} \\bobworks{\\text{For $i \\coloneqq 1$ to $\\varm$:}} \\bobworks{\\indent \\ctx.\\append(\\varL_i, \\varR_i)} \\bobworks{\\indent \\varu_i \\coloneqq \\hashtofield{\\ctx}} \\bobworks{\\indent \\varC_{i} \\coloneqq \\varu_{i}^{-1} \\cdot \\varL_{i} + \\varC_{i-1} + \\varu_{i} \\cdot \\varR_{i}} \\bobworks{\\vecg \\coloneqq \\varg(X) \\coloneqq \\prod_{i=0}^{m-1} (1 + \\varu_{m-i} X^{2^i})} \\bobworks{\\vecG_{\\varm} \\coloneqq \\ip{\\vecg}{\\vecG}} \\bobworks{\\vecb_{\\varm} \\coloneqq \\ip{\\vecg}{\\vecb}} \\bobworks{\\varC_{\\varm} \\equalQ \\ip{\\veca_{\\varm}}{\\vecG_{\\varm}} + \\ip{\\veca_{\\varm}}{\\vecb_{\\varm}} \\cdot \\varU} \\end{array} $$ Comparison with [BCMS20]. Rather than compute $\\varU \\coloneqq \\xi_0 \\cdot \\varH$ using a challenge field element $\\xi_0$, we directly ask for the challenge group element $\\varU$. These approaches are equivalent. Comparison with [BGH19]. Rather than run halving with the original polynomial and blind the outputs, $\\varL_i$, $\\varR_i$, and $\\veca_{\\varm}$, we instead run halving with a blinded polynomial $\\bar{\\varf}$. This construction has perfect completeness and, as outlined above, computational soundness. See Appendix A.3 of [BCMS20] for a proof.\nSecurity Assumptions # Discrete logarithm: The security of this protocol relies on the hardness of discrete logarithm in the group $\\cgroup$. Specifically, it assumes that there are no known discrete log relations between the random generators. Concretely, for 128-bit security consider elliptic curve groups of size greater than $2^{256}$. Security Pitfalls # Verifier input validation: Each of the items above the dotted line for the $\\varverifier$ is essential to the security of the protocol. If any of these checks are missing or insufficient it is likely a severe security issue. Weak Fiat-Shamir transform: When transforming the interactive protocol into a non-interactive protocol with the Fiat-Shamir transform, care needs to be taken to ensure that all parameters are included in the hash. See Fiat-Shamir transformation. Replay attacks: This construction does not provide replay protection; i.e., proofs can be replayed. But, replay protection can be achieved by adding more information to the $\\Hash$ invocations, see Preventing replay attacks. Verifier trusting the prover: All version of this protocol assume that the verifier does not trust the prover beyond the protocol. See the warning in Section 2 of Inner Product Argument. See also # Inner Product Argument "},{"id":25,"href":"/docs/zkdocs/protocol-primitives/alt-shamir/","title":"Alternative versions of Shamir's Secret Sharing scheme","section":"Protocol primitives","content":" Alternative Secret Sharing Solutions # There are multiple ways to prevent inadvertently sharing the secret value by evaluating the polynomial at zero. In Shamir Secret Sharing, we described defense strategies to solve that problem in classical Shamir\u0026rsquo;s Secret Sharing scheme. Here, we describe alternative implementations of Shamir\u0026rsquo;s scheme, which ensure that evaluating $f\\left(0\\right)$ does not reveal $S$.\nThese alternative schemes are certainly harder to implement (and to review), and their added complexity might not be worth the ability to mistakenly leak $f(0)$, since they can still leak the secret value by leaking other points of the polynomial. Transforming the Inputs Using a Nonzero Function # Suppose we are working over $\\z{p}$, where $p=2^{255}-19$. Consider the multiplicative group $\\zns{p}$ of integers less than $p$ and relatively prime to $p$. We can define $h\\left(m\\right)=2^{m}\\pmod{p}$. Since $0\\not\\in \\zns{p}$, we know that $h\\left(m\\right)\\neq 0$ for any integer $m$. Since $2$ is a generator of $\\zns{p}$, we know that $h\\left(m\\right)$ has maximal order in $\\zns{p}$.\nDuring share generation, given an integer input $x$, define $x\u0026rsquo;=h\\left(x\\right)$. Then, generate the corresponding share according to $\\left(x\u0026rsquo;,f\\left(x\u0026rsquo;\\right)\\right)$. Because $x\u0026rsquo;\\neq 0$, counters and external inputs can be used without the risk of generating a zero share.\nThis technique is compatible with the secret reconstruction using Lagrange interpolation: as far as the Lagrange interpolating polynomial goes, a share formed from the transformed values works the same as any other shares.\nAvoiding the $y$-intercept # It is possible to encode the secret $S$ into a polynomial such that $f\\left(t\\right)=S$ for a value $t\\neq 0$. The process is only a little more complicated than the standard Shamir scheme:\nSelect a non-zero $t\\in\\field{p}$ Select a random degree-$(k-1)$ polynomial $g\\left(x\\right)\\in\\field{p}\\left[x\\right]$ Compute $S\u0026rsquo;=S-g\\left(t\\right)$ Set the final polynomial to $f\\left(x\\right)=g\\left(x\\right)+S'$ We now have $f\\left(t\\right)=g\\left(t\\right)+S\u0026rsquo;=g\\left(t\\right)+S-g\\left(t\\right)=S$. The Lagrange interpolating polynomial can compute $f\\left(x\\right)$ at $x=t$ just as easily as at $x=0$.\nIf shares are generated sequentially, selecting a value of $t$ larger than any reasonable number of shares $n$ (e.g., $t\\gg 2^{64}$) can prevent creating an insecure share of the form $\\left(t,f\\left(t\\right)\\right)$.\nIf shares are generated randomly, it\u0026rsquo;s still possible to wind up with an insecure share by randomly selecting $t$. However, generating this value at random is significantly less likely than accidentally \u0026ldquo;generating\u0026rdquo; a zero share from a blocked read.\nMoving Away from the Constant Term # There is no requirement that $S$ be encoded into $f\\left(x\\right)$ through the manipulation of the constant coefficient. It\u0026rsquo;s possible to encode $S$ into, say, the linear coefficient of $f\\left(x\\right)$. Recovering the linear coefficient is straightforward, once you realize that the linear term of $f\\left(x\\right)$ is the constant term of $f\u0026rsquo;\\left(x \\right)$, the derivative of $f\\left(x\\right)$.\nThe process for generating a polynomial becomes:\nGenerate a random, degree-$(k-3)$ polynomial $g\\left(x\\right)$ Select a random $c\\in\\field{p}$ Set $f\\left(x\\right)=g\\left(x\\right)x^2+Sx+c$ The Lagrange interpolating polynomial can be adapted to evaluate derivatives of polynomials; the equation used to compute the first derivative is below. The equation is slightly more complicated than before but certainly within the capability of a good programmer.\n$$f\u0026rsquo;\\left(t\\right)=\\displaystyle\\sum_{j=1}^{k}{y_{j}\\left(\\displaystyle\\sum_{\\begin{smallmatrix}i=1\\\\ i\\neq j\\end{smallmatrix}}^{k}{\\left[\\frac{1}{x_{j}-x_{i}}\\displaystyle\\prod_{\\begin{smallmatrix}m=1\\\\ m\\neq i,j\\end{smallmatrix}}^{k}{\\frac{t-x_{m}}{x_{j}-x_{m}}}\\right]}\\right)}$$\nEvaluating $f\u0026rsquo;\\left(0\\right)$ gives the linear coefficient of $f\\left(x\\right)$, recovering $S$.\nRequiring Recovery of the Full Polynomial # Finally, it\u0026rsquo;s possible to encode the secret across all coefficients of $f\\left(x\\right)$. Take $g\\left(x\\right)=\\displaystyle\\sum_{i=0}^{k-1}{a_{i}x^{i}}$ , where each $a_{i}$ is chosen uniformly at random (except that $a_{k-1}\\neq 0$), then we can set $M=\\displaystyle\\sum_{i=0}^{k-1}{a_{i}}$ and $R=S - M$. We then select a random $0\\leq i\\leq k-1$ and set $f\\left(x\\right)=g\\left(x\\right)+Rx^i$. Then the sum of the coefficients is equal to $S$.\nGoing back to the original Lagrange interpolating polynomial equation, if $t$ is replaced with a symbol $x$, the Lagrange interpolating polynomial recovers $f\\left(x\\right)$ exactly. $S$ can then be recovered from the reconstructed polynomial. Symbolic computations are more expensive and slightly more complex, but for, say, $k\u0026lt;30$, the algorithm works just fine.\n"},{"id":26,"href":"/docs/zkdocs/bibliography/","title":"Bibliography","section":"Introduction","content":" References # Here, we gather a list with all references used throughout the website, sorted by year.\n[BN05] Paulo S. L. M. Barreto and Michael Naehrig. 2005. Pairing-Friendly elliptic curves of prime order. In Proceedings of the 12th international conference on Selected Areas in Cryptography (SAC\u0026#39;05). Springer-Verlag, Berlin, Heidelberg, 319â€“331. https://doi.org/10.1007/11693383_22. [Sha79] Shamir, A. (1979). How to share a secret. Communications of the ACM, 22(11), 612-613. (1979). [Fel87] Feldman, P. (1987, October). A practical scheme for non-interactive verifiable secret sharing. In 28th Annual Symposium on Foundations of Computer Science (sfcs 1987) (pp. 427-438). IEEE. (1987). [Sch91] Schnorr, C. P. (1991). Efficient signature generation by smart cards. Journal of cryptology, 4(3), 161-174 (1991). [Gir91] Girault, M. (1991, April). Self-certified public keys. In Workshop on the Theory and Application of of Cryptographic Techniques (pp. 490-497). Springer, Berlin, Heidelberg. (1991). [FO97] Fujisaki, E., \u0026amp; Okamoto, T. (1997, August). Statistical zero knowledge protocols to prove modular polynomial relations. In Annual International Cryptology Conference (pp. 16-30). Springer, Berlin, Heidelberg. (1997). [PS00] Poupard, G., \u0026amp; Stern, J. (2000, January). Short proofs of knowledge for factoring. In International Workshop on Public Key Cryptography (pp. 147-166). Springer, Berlin, Heidelberg. (2000). [Poi00] Pointcheval, D. (2000, January). The composite discrete logarithm and secure authentication. In International Workshop on Public Key Cryptography (pp. 113-128). Springer, Berlin, Heidelberg. (2000). [KZG2010] Kate, A., Zaverucha, G. M., \u0026amp; Goldberg, I. (2010, December). Constant-size commitments to polynomials and their applications. In International conference on the theory and application of cryptology and information security (pp. 177-194). Springer, Berlin, Heidelberg.\u0026#34; (2010). [BPW12] Bernhard, D., Pereira, O., \u0026amp; Warinschi, B. (2012, December). How not to prove yourself: Pitfalls of the Fiat-Shamir heuristic and applications to Helios. In International Conference on the Theory and Application of Cryptology and Information Security (pp. 626-643). Springer, Berlin, Heidelberg (2012). [BCCGP16] Bootle, J., Cerulli, A., Chaidos, P., Groth, J., \u0026amp; Petit, C. (2016). Efficient zero-knowledge arguments for arithmetic circuits in the discrete log setting. In Advances in Cryptology-EUROCRYPT 2016: 35th Annual International Conference on the Theory and Applications of Cryptographic Techniques, Vienna, Austria, May 8-12, 2016, Proceedings, Part II 35 (pp. 327-357). Springer Berlin Heidelberg. (2016). [GGN16] Gennaro, R., Goldfeder, S., \u0026amp; Narayanan, A. (2016, June). Threshold-optimal DSA/ECDSA signatures and an application to Bitcoin wallet security. In International Conference on Applied Cryptography and Network Security (pp. 156-174). Springer, Cham. (2016). [Groth16] Groth, J. (2016, May). On the size of pairing-based non-interactive arguments. In Annual international conference on the theory and applications of cryptographic techniques (pp. 305-326). Springer, Berlin, Heidelberg. (2016). [SHA3] Kelsey, J., Chang, S. J., \u0026amp; Perlner, R. (2016). SHA-3 derived functions: cSHAKE, KMAC, TupleHash and ParallelHash. NIST special publication, 800, 185. (2016). [RFC] RFC: Schnorr Non-interactive Zero-Knowledge Proof (2017). [AP18] Auerbach, B., \u0026amp; Poettering, B. (2018, March). Hashing solutions instead of generating problems: on the interactive certification of RSA moduli. In IACR International Workshop on Public Key Cryptography (pp. 403-430). Springer, Cham. (2018). [BBBPWM18] BÃ¼nz, B., Bootle, J., Boneh, D., Poelstra, A., Wuille, P., \u0026amp; Maxwell, G. (2018, May). Bulletproofs: Short proofs for confidential transactions and more. In 2018 IEEE symposium on security and privacy (SP) (pp. 315-334). IEEE. (2018). [HOC] Menezes, A. J., Van Oorschot, P. C., \u0026amp; Vanstone, S. A. (2018). Handbook of Applied Cryptography. CRC press. (2018). [PLONK] Gabizon, A., Williamson, Z. J., \u0026amp; Ciobotaru, O. (2019). Plonk: Permutations over lagrange-bases for oecumenical noninteractive arguments of knowledge. Cryptology ePrint Archive. (2019). [GRSB19] Goldberg, S., Reyzin, L., Sagga, O., \u0026amp; Baldimtsi, F. (2019, December). Efficient noninteractive certification of RSA moduli and beyond. In International Conference on the Theory and Application of Cryptology and Information Security (pp. 700-727). Springer, Cham. (2019). [BGH19] Bowe, S., Grigg, J., \u0026amp; Hopwood, D. (2019). Recursive proof composition without a trusted setup. Cryptology ePrint Archive. (2019). [BCMS20] BÃ¼nz, B., Chiesa, A., Mishra, P., \u0026amp; Spooner, N. (2020). Recursive proof composition from accumulation schemes. In Theory of Cryptography: 18th International Conference, TCC 2020, Durham, NC, USA, November 16-19, 2020, Proceedings, Part II 18 (pp. 1-18). Springer International Publishing. (2020). [NSPUE2] National Institute of Standards and Technology (2020, May). Recommendation for Key Management: Part 1 â€” General. Special Publication 800-57 Part 1, Revision 5 (2020). [GG21] Canetti, R., Gennaro, R., Goldfeder, S., Makriyannis, N., \u0026amp; Peled, U. (2020, October). UC non-interactive, proactive, threshold ECDSA with identifiable aborts. In Proceedings of the 2020 ACM SIGSAC Conference on Computer and Communications Security (pp. 1769-1787). (2020). [GBHL22] Grigg, J., Bowe, S., Hopwood, D., \u0026amp; Lai Y.T. (2022). The halo2 Book. (2022). "}]